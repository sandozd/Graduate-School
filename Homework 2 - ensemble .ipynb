{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Daniel Sandoz, Final Project, Titanic Classification Ensemble ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import time \n",
    "\n",
    "# Importing SKLearn clssifiers and libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn import preprocessing\n",
    "from  sklearn.model_selection import train_test_split \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(\"C:/Users/Modeling/Documents/Predictive Models/PM Data/titanictrain.csv\", encoding='ISO-8859-1' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "np.sum(titanic.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a lot of missing values for age and cabin. It is possible to make \n",
    "# the argument to drop cabin, however not for age. We will explore this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20484acdc48>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grasp nature of data: classification\n",
    "sns.countplot(titanic['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    446.000000\n",
       "Survived         0.383838\n",
       "Pclass           2.308642\n",
       "Age             29.699118\n",
       "SibSp            0.523008\n",
       "Parch            0.381594\n",
       "Fare            32.204208\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bowen, Mr. David John \"Dai\"</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId    Survived      Pclass                         Name  \\\n",
       "count    891.000000  891.000000  891.000000                          891   \n",
       "unique          NaN         NaN         NaN                          891   \n",
       "top             NaN         NaN         NaN  Bowen, Mr. David John \"Dai\"   \n",
       "freq            NaN         NaN         NaN                            1   \n",
       "mean     446.000000    0.383838    2.308642                          NaN   \n",
       "std      257.353842    0.486592    0.836071                          NaN   \n",
       "min        1.000000    0.000000    1.000000                          NaN   \n",
       "25%      223.500000    0.000000    2.000000                          NaN   \n",
       "50%      446.000000    0.000000    3.000000                          NaN   \n",
       "75%      668.500000    1.000000    3.000000                          NaN   \n",
       "max      891.000000    1.000000    3.000000                          NaN   \n",
       "\n",
       "         Sex         Age       SibSp       Parch Ticket        Fare    Cabin  \\\n",
       "count    891  714.000000  891.000000  891.000000    891  891.000000      204   \n",
       "unique     2         NaN         NaN         NaN    681         NaN      147   \n",
       "top     male         NaN         NaN         NaN   1601         NaN  B96 B98   \n",
       "freq     577         NaN         NaN         NaN      7         NaN        4   \n",
       "mean     NaN   29.699118    0.523008    0.381594    NaN   32.204208      NaN   \n",
       "std      NaN   14.526497    1.102743    0.806057    NaN   49.693429      NaN   \n",
       "min      NaN    0.420000    0.000000    0.000000    NaN    0.000000      NaN   \n",
       "25%      NaN   20.125000    0.000000    0.000000    NaN    7.910400      NaN   \n",
       "50%      NaN   28.000000    0.000000    0.000000    NaN   14.454200      NaN   \n",
       "75%      NaN   38.000000    1.000000    0.000000    NaN   31.000000      NaN   \n",
       "max      NaN   80.000000    8.000000    6.000000    NaN  512.329200      NaN   \n",
       "\n",
       "       Embarked  \n",
       "count       889  \n",
       "unique        3  \n",
       "top           S  \n",
       "freq        644  \n",
       "mean        NaN  \n",
       "std         NaN  \n",
       "min         NaN  \n",
       "25%         NaN  \n",
       "50%         NaN  \n",
       "75%         NaN  \n",
       "max         NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics behind the training data\n",
    "titanic.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2048442bb08>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Class\n",
    "sns.countplot(titanic['Pclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x204844805c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Class and Survived\n",
    "sns.countplot(x = 'Survived', hue = 'Pclass', data = titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems like passenger class and survival have a strong relationship. We will explore this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x204845137c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sex\n",
    "sns.countplot(titanic['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20484567a88>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sex and Survival\n",
    "sns.countplot(x = 'Survived', hue = 'Sex', data = titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x204845178c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sibilings and Spouses\n",
    "sns.countplot(titanic['SibSp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2048464e348>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEHCAYAAABBW1qbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAATxklEQVR4nO3df/BddX3n8edLAv6gakC+sJjERtcM1dldgX6LuMxYV/pDqDXZblGcVVLKTtoZyupsZ1vazuhut87Y3W0VscNMBrSJtVIaSkkdhi0TRG07IAmwgASXlGHJd4PkK78UURnoe/+4n+/xS3JJbmLOvd9v8nzM3DnnfM7nnPuGIbxyPuecz01VIUkSwEsmXYAkaeEwFCRJHUNBktQxFCRJHUNBktQxFCRJnSV9nTjJKcBfzGt6A/ARYGNrXwk8BLy3qp5IEuAy4FzgGeBXquqOfX3HCSecUCtXrjzktUvS4Wzbtm3fqqqpYfsyjvcUkhwF/D/grcDFwONV9fEklwLHVdVvJzkXuIRBKLwVuKyq3rqv805PT9fWrVt7rl6SDi9JtlXV9LB94xo+Ohv4x6r6v8BqYENr3wCsaeurgY01cCuwNMnJY6pPksT4QuF84Att/aSqegSgLU9s7cuAnfOOmWltkqQx6T0UkhwDvAf4y/11HdK219hWknVJtibZOjs7eyhKlCQ147hSOAe4o6oebduPzg0LteXu1j4DrJh33HJg154nq6r1VTVdVdNTU0Pvk0iSDtI4QuH9/HDoCGAzsLatrwWun9d+QQbOBJ6aG2aSJI1Hb4+kAiR5BfCzwK/Na/44cE2Si4CHgfNa+w0MnjzaweCR1Av7rE2StLdeQ6GqngFes0fbYwyeRtqzbzF4XFWSNCG+0SxJ6hgKkqROr8NHk/CT/3njpEsYatv/uGDSJUjSfnmlIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnq9BoKSZYm2ZTk/iTbk7wtyfFJbkryQFse1/omyaeS7Ehyd5LT+6xNkrS3vq8ULgNurKqfAN4CbAcuBbZU1SpgS9sGOAdY1T7rgCt6rk2StIfeQiHJq4C3A1cBVNWzVfUksBrY0LptANa09dXAxhq4FVia5OS+6pMk7a3PK4U3ALPAZ5PcmeTKJMcCJ1XVIwBteWLrvwzYOe/4mdYmSRqTPkNhCXA6cEVVnQZ8lx8OFQ2TIW21V6dkXZKtSbbOzs4emkolSUC/oTADzFTVbW17E4OQeHRuWKgtd8/rv2Le8cuBXXuetKrWV9V0VU1PTU31VrwkHYl6C4Wq+iawM8kprels4D5gM7C2ta0Frm/rm4EL2lNIZwJPzQ0zSZLGY0nP578E+HySY4AHgQsZBNE1SS4CHgbOa31vAM4FdgDPtL6SpDHqNRSq6i5gesius4f0LeDiPuuRJO2bbzRLkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjq9hkKSh5Lck+SuJFtb2/FJbkryQFse19qT5FNJdiS5O8npfdYmSdrbOK4U/k1VnVpV0237UmBLVa0CtrRtgHOAVe2zDrhiDLVJkuaZxPDRamBDW98ArJnXvrEGbgWWJjl5AvVJ0hGr71Ao4G+TbEuyrrWdVFWPALTlia19GbBz3rEzrU2SNCZLej7/WVW1K8mJwE1J7t9H3wxpq706DcJlHcDrXve6Q1OlJAno+Uqhqna15W7gOuAM4NG5YaG23N26zwAr5h2+HNg15Jzrq2q6qqanpqb6LF+Sjji9hUKSY5O8cm4d+DngXmAzsLZ1Wwtc39Y3Axe0p5DOBJ6aG2aSJI1Hn8NHJwHXJZn7nj+vqhuT3A5ck+Qi4GHgvNb/BuBcYAfwDHBhj7VJkoboLRSq6kHgLUPaHwPOHtJewMV91SNJ2j/faJYkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVKn91BIclSSO5N8sW2/PsltSR5I8hdJjmntL23bO9r+lX3XJkl6oXFcKXwI2D5v+w+BT1TVKuAJ4KLWfhHwRFW9EfhE6ydJGqNeQyHJcuAXgCvbdoB3Aptalw3Amra+um3T9p/d+kuSxqTvK4VPAr8F/FPbfg3wZFU917ZngGVtfRmwE6Dtf6r1lySNSW+hkOTdwO6q2ja/eUjXGmHf/POuS7I1ydbZ2dlDUKkkac5IoZBkyyhtezgLeE+Sh4CrGQwbfRJYmmRJ67Mc2NXWZ4AV7dxLgFcDj+950qpaX1XTVTU9NTU1SvmSpBHtMxSSvCzJ8cAJSY5Lcnz7rAReu69jq+p3qmp5Va0Ezgdurqp/D3wJ+OXWbS1wfVvf3LZp+2+uqr2uFCRJ/Vmyn/2/BnyYQQBs44dDPN8G/uQgv/O3gauT/AFwJ3BVa78K+FySHQyuEM4/yPNLkg7SPkOhqi4DLktySVVdfrBfUlW3ALe09QeBM4b0+T5w3sF+hyTpR7e/KwUAquryJP8aWDn/mKra2FNdkqQJGCkUknwO+OfAXcDzrbkAQ0GSDiMjhQIwDbzZG7+SdHgb9T2Fe4F/1mchkqTJG/VK4QTgviRfA34w11hV7+mlKknSRIwaCv+lzyIkSQvDqE8ffbnvQiRJkzfq00ff4YfzEB0DHA18t6pe1VdhkqTxG/VK4ZXzt5OsYcgLaJKkxe2gZkmtqr9mMMGdJOkwMurw0S/N23wJg/cWfGdBkg4zoz599Ivz1p8DHmLwS2mSpMPIqPcULuy7EEnS5I36IzvLk1yXZHeSR5Nc235/WZJ0GBn1RvNnGfwIzmsZ/Jby37Q2SdJhZNRQmKqqz1bVc+3zp4C/hSlJh5lRQ+FbST6Q5Kj2+QDwWJ+FSZLGb9RQ+FXgvcA3gUcY/IayN58l6TAz6iOp/w1YW1VPACQ5HvifDMJCknSYGPVK4V/NBQJAVT0OnNZPSZKkSRk1FF6S5Li5jXalMOpVhiRpkRj1f+x/BPxDkk0Mprd4L/CxfR2Q5GXAV4CXtu/ZVFUfTfJ64GrgeOAO4INV9WySlzL4zeefZHAT+31V9dCB/yNJkg7WSFcKVbUR+HfAo8As8EtV9bn9HPYD4J1V9RbgVOBdSc4E/hD4RFWtAp4ALmr9LwKeqKo3Ap9o/SRJYzTyLKlVdV9VfbqqLq+q+0boX1X1dNs8un2Kweyqm1r7BmBNW1/dtmn7z06SUeuTJP3oDmrq7FG1dxruAnYDNwH/CDxZVc+1LjMM3pCmLXcCtP1PAa/psz5J0gv1GgpV9XxVnQosZ/CjPG8a1q0th10V7DU9d5J1SbYm2To7O3voipUk9RsKc6rqSeAW4ExgaZK5G9zLgV1tfQZYAdD2vxp4fMi51lfVdFVNT00504YkHUq9hUKSqSRL2/rLgZ8BtgNfYvBGNMBa4Pq2vrlt0/bfXFX+kI8kjVGf7xqcDGxIchSD8Lmmqr6Y5D7g6iR/ANwJXNX6XwV8LskOBlcI5/dYmyRpiN5CoaruZshbz1X1IIP7C3u2fx84r696JEn7N5Z7CpKkxcFQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1eguFJCuSfCnJ9iRfT/Kh1n58kpuSPNCWx7X2JPlUkh1J7k5yel+1SZKG6/NK4TngN6vqTcCZwMVJ3gxcCmypqlXAlrYNcA6wqn3WAVf0WJskaYjeQqGqHqmqO9r6d4DtwDJgNbChddsArGnrq4GNNXArsDTJyX3VJ0na21juKSRZCZwG3AacVFWPwCA4gBNbt2XAznmHzbQ2SdKY9B4KSX4MuBb4cFV9e19dh7TVkPOtS7I1ydbZ2dlDVaYkiZ5DIcnRDALh81X1V6350blhobbc3dpngBXzDl8O7NrznFW1vqqmq2p6amqqv+Il6QjU59NHAa4CtlfVH8/btRlY29bXAtfPa7+gPYV0JvDU3DCTJGk8lvR47rOADwL3JLmrtf0u8HHgmiQXAQ8D57V9NwDnAjuAZ4ALe6xNkjREb6FQVX/H8PsEAGcP6V/AxX3VI0naP99oliR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUmfJpAvQCz38+/9y0iUM9bqP3DPpEiSNQW9XCkk+k2R3knvntR2f5KYkD7Tlca09ST6VZEeSu5Oc3lddkqQX1+fw0Z8C79qj7VJgS1WtAra0bYBzgFXtsw64ose6JEkvordQqKqvAI/v0bwa2NDWNwBr5rVvrIFbgaVJTu6rNknScOO+0XxSVT0C0JYntvZlwM55/WZamyRpjBbK00cZ0lZDOybrkmxNsnV2drbnsiTpyDLuUHh0blioLXe39hlgxbx+y4Fdw05QVeurarqqpqempnotVpKONOMOhc3A2ra+Frh+XvsF7SmkM4Gn5oaZJEnj09t7Ckm+ALwDOCHJDPBR4OPANUkuAh4GzmvdbwDOBXYAzwAX9lWXJOnF9RYKVfX+F9l19pC+BVzcVy2SpNEslBvNkqQFwGkudEiddflZky5hqL+/5O8nXYK0KHilIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpM6CCoUk70ryjSQ7klw66Xok6UizYEIhyVHAnwDnAG8G3p/kzZOtSpKOLEsmXcA8ZwA7qupBgCRXA6uB+yZalY4YX377T0+6hBf101/58qRL6N3HPvDLky5hqN/7s02TLmGsFlIoLAN2ztueAd46oVqkRefTv/k3ky5hqN/4o1+cdAljsf1jN0+6hKHe9HvvPKD+qaqeSjkwSc4Dfr6q/kPb/iBwRlVdske/dcC6tnkK8I0eyzoB+FaP5++b9U/OYq4drH/S+q7/x6tqatiOhXSlMAOsmLe9HNi1Z6eqWg+sH0dBSbZW1fQ4vqsP1j85i7l2sP5Jm2T9C+ZGM3A7sCrJ65McA5wPbJ5wTZJ0RFkwVwpV9VyS3wD+F3AU8Jmq+vqEy5KkI8qCCQWAqroBuGHSdcwzlmGqHln/5Czm2sH6J21i9S+YG82SpMlbSPcUJEkTZigMsdin20jymSS7k9w76VoOVJIVSb6UZHuSryf50KRrOhBJXpbka0n+d6v/v066poOR5Kgkdyb54qRrOVBJHkpyT5K7kmyddD0HKsnSJJuS3N/+HLxtrN/v8NELtek2/g/wswwek70deH9VLZo3q5O8HXga2FhV/2LS9RyIJCcDJ1fVHUleCWwD1iyWf/9JAhxbVU8nORr4O+BDVXXrhEs7IEn+EzANvKqq3j3peg5EkoeA6apalO8pJNkAfLWqrmxPYr6iqp4c1/d7pbC3brqNqnoWmJtuY9Goqq8Aj0+6joNRVY9U1R1t/TvAdgZvuy8KNfB02zy6fRbV37ySLAd+Abhy0rUcaZK8Cng7cBVAVT07zkAAQ2GYYdNtLJr/KR1OkqwETgNum2wlB6YNvdwF7AZuqqpFVT/wSeC3gH+adCEHqYC/TbKtzYCwmLwBmAU+24bvrkxy7DgLMBT2liFti+pveoeDJD8GXAt8uKq+Pel6DkRVPV9VpzJ4K/+MJItmCC/Ju4HdVbVt0rX8CM6qqtMZzLh8cRtOXSyWAKcDV1TVacB3gbHe1zQU9jbSdBvqTxuLvxb4fFX91aTrOVjtsv8W4F0TLuVAnAW8p43LXw28M8mfTbakA1NVu9pyN3AdgyHhxWIGmJl3dbmJQUiMjaGwN6fbmKB2o/YqYHtV/fGk6zlQSaaSLG3rLwd+Brh/slWNrqp+p6qWV9VKBv/t31xVH5hwWSNLcmx7QIE27PJzwKJ5Cq+qvgnsTHJKazqbMf98wIJ6o3khOBym20jyBeAdwAlJZoCPVtVVk61qZGcBHwTuaePyAL/b3nZfDE4GNrSn2F4CXFNVi+6xzkXsJOC6wd8tWAL8eVXdONmSDtglwOfbX0ofBC4c55f7SKokqePwkSSpYyhIkjqGgiSpYyhIkjqGgiSpYyhI+5Hk+Tbj5r1J/jLJKw7BOX8lyacPRX3SoWQoSPv3vao6tc04+yzw66Me2N5XkBYNQ0E6MF8F3giQ5K/bpGtfnz/xWpKnk/x+ktuAtyX5qST/0H5j4Wtzb9wCr01yY5IHkvz3CfyzSHvxjWZpREmWMJhkbe4N2V+tqsfbdBa3J7m2qh4DjgXuraqPtLdS7wfeV1W3t6mRv9eOP5XBLLA/AL6R5PKq2ok0QYaCtH8vnzflxldpc90D/zHJv23rK4BVwGPA8wwm9AM4BXikqm4HmJvxtU3DsKWqnmrb9wE/zgunbZfGzlCQ9u97bSrsTpJ3MJjs7m1V9UySW4CXtd3fr6rn57ry4lOv/2De+vP451ELgPcUpIPzauCJFgg/AZz5Iv3uZ3Dv4KcAkryyDUNJC5L/cUoH50bg15PcDXwDGPobzFX1bJL3AZe3ew/fY3CFIS1IzpIqSeo4fCRJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqTO/wekPIRqxPSXagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parents and Children\n",
    "sns.countplot(titanic['Parch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x204846bf6c8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Embarked: C = Cherbourg, Q = Queenstown, S = Southhampton\n",
    "sns.countplot(titanic['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20484749c08>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# correaltion analysis\n",
    "sns.heatmap(titanic.corr(), annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is very low correlation present in the data\n",
    "# so there is no need to worry about multicollinerity. When considering the \n",
    "# issue of missing values for age, the strongest correlation is present\n",
    "# when age is compared to passenger class. With this, we will use passenger \n",
    "# class to help explain age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass\n",
      "1    37.0\n",
      "2    29.0\n",
      "3    24.0\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "age_group = titanic.groupby(\"Pclass\")[\"Age\"]\n",
    "\n",
    "print(age_group.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After dividing up the passenger class into average ages, it is apparent \n",
    "# there is a noteable difference in the average age of each passenger class.\n",
    "# We can confidently replace age in those groups with the median above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Inserting values for age\n",
    "titanic.loc[titanic.Age.isnull(), 'Age'] = titanic.groupby(\"Pclass\").Age.transform('median')\n",
    "\n",
    "print(titanic[\"Age\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "np.sum(titanic.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 2 missing values for 'embarked' with 'S' because it occurs the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(mode(titanic[\"Embarked\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "np.sum(titanic.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# transform sex\n",
    "titanic[\"Sex\"][titanic[\"Sex\"] == \"male\"] = 0\n",
    "titanic[\"Sex\"][titanic[\"Sex\"] == \"female\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# transform embarked\n",
    "titanic[\"Embarked\"][titanic[\"Embarked\"] == \"S\"] = 0\n",
    "titanic[\"Embarked\"][titanic[\"Embarked\"] == \"C\"] = 1\n",
    "titanic[\"Embarked\"][titanic[\"Embarked\"] == \"Q\"] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show variables by type\n",
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0           0       3   0  22.0      1      0   7.2500        0\n",
       "1           1       1   1  38.0      1      0  71.2833        1\n",
       "2           1       3   1  26.0      0      0   7.9250        0\n",
       "3           1       1   1  35.0      1      0  53.1000        0\n",
       "4           0       3   0  35.0      0      0   8.0500        0\n",
       "..        ...     ...  ..   ...    ...    ...      ...      ...\n",
       "886         0       2   0  27.0      0      0  13.0000        0\n",
       "887         1       1   1  19.0      0      0  30.0000        0\n",
       "888         0       3   1  24.0      1      2  23.4500        0\n",
       "889         1       1   0  26.0      0      0  30.0000        1\n",
       "890         0       3   0  32.0      0      0   7.7500        2\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we are dropping \"Name\", \"Ticket\", \"Passenger ID\" and \"Cabin\" as these are not intuitve\n",
    "# to analysis, have too many missing values, and/or add the need for more processing resources while not contributing to analysis\n",
    "\n",
    "\n",
    "titanic = titanic[['Survived','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']].copy()\n",
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    titanic.iloc[:,1:].values, titanic.iloc[:,0].values, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(357, 7)\n",
      "(534, 7)\n",
      "(357,)\n",
      "(534,)\n"
     ]
    }
   ],
   "source": [
    "# confirm split\n",
    "print(features_test.shape)\n",
    "print(features_train.shape)\n",
    "print(target_test.shape)\n",
    "print(target_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KNN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_df1 = titanic.filter(['PassengerId','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked'].copy(), axis=1)\n",
    "knn_df2 = titanic['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN 3\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn = knn.fit(features_train, target_train)\n",
    "\n",
    "\n",
    "knn_predict = knn.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score for each K [0.80555556 0.63888889 0.61111111 0.63888889 0.66666667 0.58333333\n",
      " 0.66666667 0.57142857 0.6        0.68571429]\n",
      "CV mean score:  0.6468253968253969\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation KNN = 3\n",
    "knn_cross_validate_scores = cross_val_score(knn, features_test, target_test, cv=10)\n",
    "print('CV Score for each K', knn_cross_validate_scores)\n",
    "print('CV mean score: ', knn_cross_validate_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy score:  0.6834733893557423\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76       221\n",
      "           1       0.61      0.48      0.53       136\n",
      "\n",
      "    accuracy                           0.68       357\n",
      "   macro avg       0.66      0.64      0.65       357\n",
      "weighted avg       0.67      0.68      0.67       357\n",
      "\n",
      "[[179  42]\n",
      " [ 71  65]]\n"
     ]
    }
   ],
   "source": [
    "# classification and confusion matrix \n",
    "print(\"KNN accuracy score: \",accuracy_score(target_test,knn_predict))\n",
    "print(classification_report(target_test, knn_predict))\n",
    "print(confusion_matrix(target_test, knn_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN = 5\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn = knn.fit(features_train, target_train)\n",
    "\n",
    "# predicting using test set\n",
    "knn_predict = knn.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score for each K [0.83333333 0.69444444 0.69444444 0.75       0.66666667 0.61111111\n",
      " 0.75       0.62857143 0.68571429 0.71428571]\n",
      "CV mean score:  0.7028571428571428\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation KNN = 5\n",
    "knn_cross_validate_scores = cross_val_score(knn, features_test, target_test, cv=10)\n",
    "print('CV Score for each K', knn_cross_validate_scores)\n",
    "print('CV mean score: ', knn_cross_validate_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy score:  0.711484593837535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78       221\n",
      "           1       0.66      0.51      0.57       136\n",
      "\n",
      "    accuracy                           0.71       357\n",
      "   macro avg       0.70      0.67      0.68       357\n",
      "weighted avg       0.70      0.71      0.70       357\n",
      "\n",
      "[[185  36]\n",
      " [ 67  69]]\n"
     ]
    }
   ],
   "source": [
    "# classification and confusion matrix \n",
    "print(\"KNN accuracy score: \",accuracy_score(target_test,knn_predict))\n",
    "print(classification_report(target_test, knn_predict))\n",
    "print(confusion_matrix(target_test, knn_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN 7\n",
    "knn = KNeighborsClassifier(n_neighbors = 7)\n",
    "knn = knn.fit(features_train, target_train)\n",
    "\n",
    "# predicting using test set\n",
    "knn_predict = knn.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score for each K [0.86111111 0.66666667 0.72222222 0.75       0.69444444 0.61111111\n",
      " 0.72222222 0.62857143 0.74285714 0.71428571]\n",
      "CV mean score:  0.7113492063492064\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation KNN = 7\n",
    "knn_cross_validate_scores = cross_val_score(knn, features_test, target_test, cv=10)\n",
    "print('CV Score for each K', knn_cross_validate_scores)\n",
    "print('CV mean score: ', knn_cross_validate_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy score:  0.6946778711484594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77       221\n",
      "           1       0.63      0.47      0.54       136\n",
      "\n",
      "    accuracy                           0.69       357\n",
      "   macro avg       0.68      0.65      0.66       357\n",
      "weighted avg       0.69      0.69      0.68       357\n",
      "\n",
      "[[184  37]\n",
      " [ 72  64]]\n"
     ]
    }
   ],
   "source": [
    "# classification and confusion matrix KNN = 7\n",
    "print(\"KNN accuracy score: \",accuracy_score(target_test,knn_predict))\n",
    "print(classification_report(target_test, knn_predict))\n",
    "print(confusion_matrix(target_test, knn_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I ran three different models with n-neighbor classifiers of 3,5 and 7. The\n",
    "# Knn-5 is the default value for KNN models, however it performed the best.\n",
    "# We do not have to worry about over fitting with KNN models.\n",
    "# I saw a slight increase in accuracy for KNN-5 \n",
    "# vs. KNN-3 and KNN-7. There is also an increase in precision and recall statistics\n",
    "# for KNN-5 vs. KNN-3 and KNN-7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decision Tree ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will create the default, then fit and test the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train DT model\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "# fit the DT model\n",
    "decision_tree = decision_tree.fit(features_train, target_train)\n",
    "# test the DT model\n",
    "target_predicted_dt = decision_tree.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.75925926 0.81481481 0.7962963  0.74074074 0.75471698 0.75471698\n",
      " 0.64150943 0.81132075 0.71698113 0.8490566 ]\n",
      "Cross Validation mean score:  0.7639412997903563\n"
     ]
    }
   ],
   "source": [
    "#Cross Validate Default Tree\n",
    "\n",
    "#verify DT with Cross Validation\n",
    "scores = cross_val_score(decision_tree, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "print('Cross Validation mean score: ', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy score:  0.7366946778711485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79       221\n",
      "           1       0.68      0.60      0.63       136\n",
      "\n",
      "    accuracy                           0.74       357\n",
      "   macro avg       0.72      0.71      0.71       357\n",
      "weighted avg       0.73      0.74      0.73       357\n",
      "\n",
      "[[182  39]\n",
      " [ 55  81]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix Decision Tree\n",
    "\n",
    "print(\"Decision Tree accuracy score: \",accuracy_score(target_test,target_predicted_dt))\n",
    "target_names_dt = [\"0\", \"1\"]\n",
    "print(classification_report(target_test, target_predicted_dt, target_names=target_names_dt))\n",
    "print(confusion_matrix(target_test, target_predicted_dt, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I created a decision tree from the data. The accuracy of the default model\n",
    "# is 73.66%. I cross validated with 10 repeats. This default model is \n",
    "# better at classifying not survived than survived passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.77777778 0.88888889 0.77777778 0.77777778 0.86792453 0.77358491\n",
      " 0.77358491 0.86792453 0.83018868 0.83018868]\n",
      "Cross Validation mean score:  0.8165618448637316\n",
      "Decision Tree2 accuracy score:  0.8011204481792717\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       221\n",
      "           1       0.73      0.76      0.74       136\n",
      "\n",
      "    accuracy                           0.80       357\n",
      "   macro avg       0.79      0.79      0.79       357\n",
      "weighted avg       0.80      0.80      0.80       357\n",
      "\n",
      "[[183  38]\n",
      " [ 33 103]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree 2: Max leaf nodes =10, class weight = balanced\n",
    "\n",
    "# train DT2 model\n",
    "decision_tree2 = tree.DecisionTreeClassifier(max_leaf_nodes = 10 ,class_weight='balanced')\n",
    "# fit the DT2 model\n",
    "decision_tree2 = decision_tree2.fit(features_train, target_train)\n",
    "# test the DT2 model\n",
    "target_predicted_dt2 = decision_tree2.predict(features_test)\n",
    "# verify DT2 with Cross Validation\n",
    "scores = cross_val_score(decision_tree2, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "print('Cross Validation mean score: ', scores.mean()) \n",
    "# confusion matrix DT2\n",
    "print(\"Decision Tree2 accuracy score: \",accuracy_score(target_test,target_predicted_dt2))\n",
    "target_names_dt2 = [\"0\", \"1\"]\n",
    "print(classification_report(target_test, target_predicted_dt2, target_names=target_names_dt2))\n",
    "print(confusion_matrix(target_test, target_predicted_dt2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After viewing the default, I changed some of the parameters adding \n",
    "# max leaf nodes = 10, and a balanced weight class in search of getting a \n",
    "# stonger model. With the new parameters, the accuracy has increased to\n",
    "# ~ 80%. Precision, recall, and f-1 have all increased. I will continue to \n",
    "# adjust parameters to increase the stregth of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.75925926 0.83333333 0.85185185 0.7037037  0.79245283 0.77358491\n",
      " 0.66037736 0.83018868 0.71698113 0.79245283]\n",
      "Cross Validation mean score:  0.7714185883997204\n",
      "Decision Tree2 accuracy score:  0.7871148459383753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83       221\n",
      "           1       0.71      0.74      0.73       136\n",
      "\n",
      "    accuracy                           0.79       357\n",
      "   macro avg       0.77      0.78      0.78       357\n",
      "weighted avg       0.79      0.79      0.79       357\n",
      "\n",
      "[[180  41]\n",
      " [ 35 101]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree 3: Max leaf nodes =100, class weight = balanced\n",
    "\n",
    "# train DT3 model\n",
    "decision_tree3 = tree.DecisionTreeClassifier(max_leaf_nodes = 100, class_weight = 'balanced')\n",
    "# fit the DT3 model\n",
    "decision_tree3 = decision_tree3.fit(features_train, target_train)\n",
    "# test the DT3 model\n",
    "target_predicted_dt3 = decision_tree3.predict(features_test)\n",
    "# verify DT3 with Cross Validation\n",
    "scores = cross_val_score(decision_tree3, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "print('Cross Validation mean score: ', scores.mean()) \n",
    "# confusion matrix DT3\n",
    "print(\"Decision Tree2 accuracy score: \",accuracy_score(target_test,target_predicted_dt3))\n",
    "target_names_dt3 = [\"0\", \"1\"]\n",
    "print(classification_report(target_test, target_predicted_dt3, target_names=target_names_dt3))\n",
    "print(confusion_matrix(target_test, target_predicted_dt3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because there was only a slight increase in recall, I increased the max leaf\n",
    "# nodes = 100 and kept the others constant to increase the strength of the model.\n",
    "# With this, the accuracy has gone down, along with precision and recall statistics.\n",
    "# Decision Tree 2 seems to currently be the strongest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search Decision Tree\n",
    "grid_param = {'min_samples_split': [2, 5, 10, 20],'max_features': [2, 3, 4, 5, 6, 7],'max_leaf_nodes': [10, 30, 75, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST ESTM:  DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=5, max_leaf_nodes=10,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=10,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "BEST SCORE:  0.8314116002795249\n",
      "BEST PARAM:  {'max_features': 5, 'max_leaf_nodes': 10, 'min_samples_split': 10}\n"
     ]
    }
   ],
   "source": [
    "grid_dt = GridSearchCV(decision_tree, param_grid = grid_param, scoring='accuracy',cv=10)\n",
    "grid_dt.fit(features_train, target_train)\n",
    "\n",
    "print(\"BEST ESTM: \",grid_dt.best_estimator_)\n",
    "print(\"BEST SCORE: \", grid_dt.best_score_)\n",
    "print(\"BEST PARAM: \", grid_dt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.7962963  0.90740741 0.81481481 0.7962963  0.83018868 0.73584906\n",
      " 0.79245283 0.8490566  0.83018868 0.81132075]\n",
      "Cross Validation mean score:  0.81638714185884\n",
      "Decision Tree Best accuracy score:  0.8067226890756303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.85       221\n",
      "           1       0.83      0.62      0.71       136\n",
      "\n",
      "    accuracy                           0.81       357\n",
      "   macro avg       0.81      0.77      0.78       357\n",
      "weighted avg       0.81      0.81      0.80       357\n",
      "\n",
      "[[203  18]\n",
      " [ 51  85]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree 4: Best\n",
    "\n",
    "# train DT Best model\n",
    "decision_tree_best = tree.DecisionTreeClassifier(max_features= 5, max_leaf_nodes= 10, min_samples_split= 10)\n",
    "# fit the DT Best model\n",
    "decision_tree_best = decision_tree_best.fit(features_train, target_train)\n",
    "# test the DT Best model\n",
    "target_predicted_dtbest = decision_tree_best.predict(features_test)\n",
    "# verify DT Best with Cross Validation\n",
    "scores = cross_val_score(decision_tree_best, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "print('Cross Validation mean score: ', scores.mean()) \n",
    "# confusion matrix DTBest\n",
    "print(\"Decision Tree Best accuracy score: \",accuracy_score(target_test,target_predicted_dtbest))\n",
    "target_names_dtbest = [\"0\", \"1\"]\n",
    "print(classification_report(target_test, target_predicted_dtbest, target_names=target_names_dtbest))\n",
    "print(confusion_matrix(target_test, target_predicted_dtbest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To most successfully tune our hyperparameters, we utilized gridsearch.\n",
    "# Gridsearch suggested that we use 5 features, 10 leaf nodes, and a min sample\n",
    "# split of 10. When compared to the Decision Tree 2, the CV mean score, and the\n",
    "# accuracy score were practically the same. However, the weighed average accuracy\n",
    "# increased when utilizing gridsearch. Our best decision tree model is model\n",
    "# number 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "Higher the more important\n",
      "[(0.6130191, 'Sex'), (0.169758, 'Pclass'), (0.1248619, 'Fare'), (0.092361, 'Age'), (0.0, 'SibSp'), (0.0, 'Parch')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Features sorted by their score:\")\n",
    "print(\"Higher the more important\")\n",
    "print(sorted(zip(map(lambda x: round(x, 7), decision_tree_best.feature_importances_),titanic.columns[1:7]), \n",
    "             reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can see the importance of each feature, and how well they add to the \n",
    "# proper classification of survivors. It seems that sex is the strongest predictor\n",
    "# to weather or not a passenger would survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AdaBoost Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Accuracy 0.8235294117647058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       221\n",
      "           1       0.80      0.71      0.75       136\n",
      "\n",
      "    accuracy                           0.82       357\n",
      "   macro avg       0.82      0.80      0.81       357\n",
      "weighted avg       0.82      0.82      0.82       357\n",
      "\n",
      "[[197  24]\n",
      " [ 39  97]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3, max_features= 5, max_leaf_nodes= 10, min_samples_split= 10),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200)\n",
    "bdt.fit(features_train, target_train)\n",
    "predicted_bdt=bdt.predict(features_test)\n",
    "expected = target_test\n",
    "print(\"Adaboost Accuracy\", accuracy_score(expected,predicted_bdt))\n",
    "print(classification_report(expected, predicted_bdt,target_names=['0', '1']))\n",
    "print(confusion_matrix(expected, predicted_bdt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After using gridsearch to find the best parameters, I decided to use those\n",
    "# parameters in combination with the AdaBoost Classifier. This increased the \n",
    "# strength of the model across the board. Adaboosted Decision Tree with \n",
    "# respective parameters is our preferred Decision Tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "Higher the more important\n",
      "[(0.3243417, 'Age'), (0.0797912, 'Sex'), (0.0457439, 'SibSp'), (0.0354762, 'Pclass')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Features sorted by their score:\")\n",
    "print(\"Higher the more important\")\n",
    "print(sorted(zip(map(lambda x: round(x, 7), bdt.feature_importances_),titanic.columns[1:5]), \n",
    "             reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running feature importance on the preffered Decision Tree model,\n",
    "# we get a different output regarding the predictive power of each feature.\n",
    "# This model considers age to be a better explainer of survival vs. sex.  \n",
    "# However, we have to remember that we grouped age with consideration of the\n",
    "# passenger class. We will continue to analyze the feature importance to gain\n",
    "# a better understand on what the major contributors to survival are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default RF\n",
    "# train RF model\n",
    "rf = RandomForestClassifier()\n",
    "# fit the RF model\n",
    "rf = rf.fit(features_train, target_train)\n",
    "# test the RF model\n",
    "target_predicted_rf = rf.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.75925926 0.85185185 0.81481481 0.7962963  0.86792453 0.69811321\n",
      " 0.71698113 0.81132075 0.81132075 0.83018868]\n",
      "Cross Validation mean score:  0.7958071278825994\n"
     ]
    }
   ],
   "source": [
    "# Cross validate\n",
    "\n",
    "scores_rf = cross_val_score(rf, features_train, target_train, cv=10, n_jobs=-1)\n",
    "print(\"Cross Validation Score for each K\",scores_rf)\n",
    "print('Cross Validation mean score: ', scores_rf.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy score:  0.8067226890756303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       221\n",
      "           1       0.77      0.71      0.74       136\n",
      "\n",
      "    accuracy                           0.81       357\n",
      "   macro avg       0.80      0.79      0.79       357\n",
      "weighted avg       0.80      0.81      0.80       357\n",
      "\n",
      "[[192  29]\n",
      " [ 40  96]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "print(\"Random Forest accuracy score: \",accuracy_score(target_test,target_predicted_rf))\n",
    "target_names_rf = [\"0\", \"1\"]\n",
    "print(classification_report(target_test, target_predicted_rf, target_names=target_names_rf))\n",
    "print(confusion_matrix(target_test, target_predicted_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After creating a Random Forest model, the accuracy is ~ 80%, with precision,\n",
    "# recall, and f-1 scores at 80%, 79%, and 80% respectivly. We will continue\n",
    "# to adjust hyperparameters in search of increasing these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run 2.2537172000156716 seconds\n",
      "{'mean_fit_time': array([0.21502547, 0.21821699, 0.21941552, 0.231182  , 0.2086484 ]), 'std_fit_time': array([0.00566276, 0.003646  , 0.00296326, 0.00589683, 0.0346643 ]), 'mean_score_time': array([0.01336474, 0.0135632 , 0.01296301, 0.01276565, 0.00917549]), 'std_score_time': array([0.00048856, 0.00048788, 0.00063063, 0.00074648, 0.00193362]), 'param_max_features': masked_array(data=[2, 3, 4, 5, 6],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_features': 2}, {'max_features': 3}, {'max_features': 4}, {'max_features': 5}, {'max_features': 6}], 'split0_test_score': array([0.79439252, 0.80373832, 0.8317757 , 0.81308411, 0.80373832]), 'split1_test_score': array([0.80373832, 0.81308411, 0.80373832, 0.81308411, 0.8411215 ]), 'split2_test_score': array([0.77570093, 0.78504673, 0.76635514, 0.76635514, 0.75700935]), 'split3_test_score': array([0.76635514, 0.76635514, 0.77570093, 0.77570093, 0.77570093]), 'split4_test_score': array([0.81132075, 0.82075472, 0.81132075, 0.80188679, 0.81132075]), 'mean_test_score': array([0.79030153, 0.7977958 , 0.79777817, 0.79402222, 0.79777817]), 'std_test_score': array([0.01688608, 0.01973429, 0.02387286, 0.01944068, 0.02914471]), 'rank_test_score': array([5, 1, 2, 4, 2])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch to identify features\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_features\": [2, 3, 4, 5, 6,]}\n",
    "start_time = time.clock()\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(rf, param_grid=param_grid,n_jobs=-1)\n",
    "\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "print(\"Time to run\", time.clock() - start_time, \"seconds\")\n",
    "print(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "Higher the more important\n",
      "[(0.2643, 'Sex'), (0.2611, 'Age'), (0.2551, 'Fare'), (0.0898, 'Pclass'), (0.0532, 'SibSp'), (0.0382, 'Parch'), (0.0382, 'Embarked')]\n"
     ]
    }
   ],
   "source": [
    "#Feature Importance\n",
    "print(\"Features sorted by their score:\")\n",
    "print(\"Higher the more important\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_),titanic.columns[1:100]), \n",
    "             reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.74074074 0.87037037 0.81481481 0.77777778 0.8490566  0.71698113\n",
      " 0.71698113 0.81132075 0.81132075 0.83018868]\n",
      "Cross Validation mean score:  0.7939552760307478\n",
      "Random Forest accuracy score:  0.7927170868347339\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84       221\n",
      "           1       0.74      0.70      0.72       136\n",
      "\n",
      "    accuracy                           0.79       357\n",
      "   macro avg       0.78      0.77      0.78       357\n",
      "weighted avg       0.79      0.79      0.79       357\n",
      "\n",
      "[[188  33]\n",
      " [ 41  95]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest 2: estimators = 500, jobs =-1, oob score = True\n",
    "\n",
    "# train RF2 model\n",
    "rf2 = RandomForestClassifier(n_estimators= 500, n_jobs=-1,oob_score=True)\n",
    "# fit the RF2 model\n",
    "rf2 = rf2.fit(features_train, target_train)\n",
    "# test the RF2 model\n",
    "target_predicted_rf2 = rf2.predict(features_test)\n",
    "# cross validate RF2 model\n",
    "scores_rf2 = cross_val_score(rf2, features_train, target_train, cv=10, n_jobs=-1)\n",
    "print(\"Cross Validation Score for each K\",scores_rf2)\n",
    "print('Cross Validation mean score: ', scores_rf2.mean())\n",
    "# confusion matrix RF2 model\n",
    "print(\"Random Forest accuracy score: \",accuracy_score(target_test,target_predicted_rf2))\n",
    "target_names_rf2 = [\"0\", \"1\"]\n",
    "print(classification_report(target_test, target_predicted_rf2, target_names=target_names_rf2))\n",
    "print(confusion_matrix(target_test, target_predicted_rf2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After increasing the number of bootstrapped trees to 500, jobs =-1, and \n",
    "# oob score = true, the model returned a very similar output, however slightly\n",
    "# decreasing all accuracy statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.75925926 0.85185185 0.81481481 0.77777778 0.8490566  0.73584906\n",
      " 0.71698113 0.81132075 0.81132075 0.83018868]\n",
      "Cross Validation mean score:  0.7958420684835779\n",
      "Random Forest accuracy score:  0.7983193277310925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       221\n",
      "           1       0.75      0.71      0.73       136\n",
      "\n",
      "    accuracy                           0.80       357\n",
      "   macro avg       0.79      0.78      0.78       357\n",
      "weighted avg       0.80      0.80      0.80       357\n",
      "\n",
      "[[189  32]\n",
      " [ 40  96]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest 3: estimators = 100, jobs =-1, oob score = True\n",
    "\n",
    "\n",
    "# train RF3 model\n",
    "rf3 = RandomForestClassifier(n_estimators= 100, n_jobs=-1,oob_score=True)\n",
    "# fit the RF3 model\n",
    "rf3 = rf3.fit(features_train, target_train)\n",
    "# test the RF3 model\n",
    "target_predicted_rf3 = rf3.predict(features_test)\n",
    "# cross validate RF3 model\n",
    "scores_rf3 = cross_val_score(rf3, features_train, target_train, cv=10, n_jobs=-1)\n",
    "print(\"Cross Validation Score for each K\",scores_rf3)\n",
    "print('Cross Validation mean score: ', scores_rf3.mean())\n",
    "# confusion matrix RF3 model\n",
    "print(\"Random Forest accuracy score: \",accuracy_score(target_test,target_predicted_rf3))\n",
    "target_names_rf3 = [\"0\", \"1\"]\n",
    "print(classification_report(target_test, target_predicted_rf3, target_names=target_names_rf3))\n",
    "print(confusion_matrix(target_test, target_predicted_rf3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After changing the number of bootstrapped trees to 100, jobs =-1, and \n",
    "# oob score = true, the model returned a very similar output to the default,\n",
    "# however slightly decreasing accuracy and recall statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridsearch Random Forest\n",
    "\n",
    "param_grid_rf = {'bootstrap': [True],'max_depth': [2, 3, 10, 110],'max_features': [3, 4, 5],'min_samples_leaf': [ 4, 5, 6,],'min_samples_split': [5, 7, 9],'n_estimators': [50, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 276 tasks      | elapsed:    7.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST ESTM:  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=110, max_features=4,\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=5, min_samples_split=5,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "BEST SCORE:  0.8220973782771536\n",
      "BEST PARAM:  {'bootstrap': True, 'max_depth': 110, 'max_features': 4, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 648 out of 648 | elapsed:   19.6s finished\n"
     ]
    }
   ],
   "source": [
    "grid_rf = GridSearchCV(estimator = rf, param_grid = param_grid_rf, cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_rf.fit(features_train, target_train)\n",
    "print(\"BEST ESTM: \", grid_rf.best_estimator_)\n",
    "print(\"BEST SCORE: \", grid_rf.best_score_)\n",
    "print(\"BEST PARAM: \", grid_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.7962963  0.87037037 0.83333333 0.77777778 0.83018868 0.77358491\n",
      " 0.77358491 0.86792453 0.83018868 0.8490566 ]\n",
      "Cross Validation mean score:  0.820230607966457\n",
      "Random Forest accuracy score:  0.8207282913165266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.86       221\n",
      "           1       0.83      0.66      0.74       136\n",
      "\n",
      "    accuracy                           0.82       357\n",
      "   macro avg       0.82      0.79      0.80       357\n",
      "weighted avg       0.82      0.82      0.82       357\n",
      "\n",
      "[[203  18]\n",
      " [ 46  90]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Best\n",
    "\n",
    "# train RF Best model\n",
    "rfbest1 = RandomForestClassifier(bootstrap= True, max_depth= 110, max_features= 4, min_samples_leaf= 5, min_samples_split= 5, n_estimators= 50)\n",
    "# fit the RF Best model\n",
    "rfbest = rfbest1.fit(features_train, target_train)\n",
    "# test the RF Best model\n",
    "target_predicted_rfbest = rfbest.predict(features_test)\n",
    "# cross validate RF Best model\n",
    "scores_rfbest = cross_val_score(rfbest, features_train, target_train, cv=10, n_jobs=-1)\n",
    "print(\"Cross Validation Score for each K\",scores_rfbest)\n",
    "print('Cross Validation mean score: ', scores_rfbest.mean()) \n",
    "\n",
    "# confusion matrix RF2 model\n",
    "print(\"Random Forest accuracy score: \",accuracy_score(target_test,target_predicted_rfbest))\n",
    "target_names_rfbest = [\"0\", \"1\"]\n",
    "print(classification_report(target_test, target_predicted_rfbest, target_names=target_names_rfbest))\n",
    "print(confusion_matrix(target_test, target_predicted_rfbest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After using Gridsearch to find the best hyperparameters, we were able to \n",
    "# increase our overall accuracy, and accuracy statistics to an accuracy of \n",
    "# 82%. We can now inspect what features add the most strength to the \n",
    "# strongest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run 1.7381523000003654 seconds\n",
      "{'mean_fit_time': array([0.10691462, 0.10551796, 0.10950618, 0.12785826, 0.13105168]), 'std_fit_time': array([0.00270603, 0.00544163, 0.00603036, 0.01696524, 0.0177803 ]), 'mean_score_time': array([0.00678229, 0.00678215, 0.00698142, 0.00718079, 0.00618081]), 'std_score_time': array([3.98874326e-04, 3.98683676e-04, 1.78416128e-07, 3.99780416e-04,\n",
      "       1.32348737e-03]), 'param_max_features': masked_array(data=[2, 3, 4, 5, 6],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_features': 2}, {'max_features': 3}, {'max_features': 4}, {'max_features': 5}, {'max_features': 6}], 'split0_test_score': array([0.82242991, 0.82242991, 0.85046729, 0.8411215 , 0.8411215 ]), 'split1_test_score': array([0.81308411, 0.80373832, 0.79439252, 0.81308411, 0.81308411]), 'split2_test_score': array([0.78504673, 0.80373832, 0.80373832, 0.76635514, 0.78504673]), 'split3_test_score': array([0.82242991, 0.85046729, 0.82242991, 0.8317757 , 0.82242991]), 'split4_test_score': array([0.8490566 , 0.83962264, 0.82075472, 0.8490566 , 0.83962264]), 'mean_test_score': array([0.81840945, 0.82399929, 0.81835655, 0.82027861, 0.82026098]), 'std_test_score': array([0.02055727, 0.0188049 , 0.01919068, 0.02951028, 0.02052457]), 'rank_test_score': array([4, 1, 5, 2, 3])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch to identify features\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_features\": [2, 3, 4, 5, 6,]}\n",
    "start_time = time.clock()\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(rfbest, param_grid=param_grid,n_jobs=-1)\n",
    "\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "print(\"Time to run\", time.clock() - start_time, \"seconds\")\n",
    "print(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "Higher the more important\n",
      "[(0.4755, 'Sex'), (0.1718, 'Fare'), (0.1584, 'Age'), (0.1051, 'Pclass'), (0.0449, 'SibSp'), (0.0299, 'Embarked'), (0.0145, 'Parch')]\n"
     ]
    }
   ],
   "source": [
    "#Feature Importance\n",
    "print(\"Features sorted by their score:\")\n",
    "print(\"Higher the more important\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rfbest.feature_importances_),titanic.columns[1:100]), \n",
    "             reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we can again see that 'sex' is the biggest contributor to whether or\n",
    "# not an individual survived on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AdaBoost Random Forest - takes time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Accuracy 0.7955182072829131\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84       221\n",
      "           1       0.74      0.72      0.73       136\n",
      "\n",
      "    accuracy                           0.80       357\n",
      "   macro avg       0.78      0.78      0.78       357\n",
      "weighted avg       0.79      0.80      0.80       357\n",
      "\n",
      "[[186  35]\n",
      " [ 38  98]]\n"
     ]
    }
   ],
   "source": [
    "# Adaboost (default)\n",
    "bdt = AdaBoostClassifier((rf),\n",
    "                         algorithm=\"SAMME\")\n",
    "bdt.fit(features_train, target_train)\n",
    "predicted_bdt=bdt.predict(features_test)\n",
    "expected = target_test\n",
    "print(\"Adaboost Accuracy\", accuracy_score(expected,predicted_bdt))\n",
    "print(classification_report(expected, predicted_bdt,target_names=['0', '1']))\n",
    "print(confusion_matrix(expected, predicted_bdt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Accuracy 0.7759103641456583\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       221\n",
      "           1       0.71      0.69      0.70       136\n",
      "\n",
      "    accuracy                           0.78       357\n",
      "   macro avg       0.76      0.76      0.76       357\n",
      "weighted avg       0.77      0.78      0.78       357\n",
      "\n",
      "[[183  38]\n",
      " [ 42  94]]\n"
     ]
    }
   ],
   "source": [
    "# Adaboost (rfbest)\n",
    "bdt = AdaBoostClassifier((rfbest),\n",
    "                         algorithm=\"SAMME\")\n",
    "bdt.fit(features_train, target_train)\n",
    "predicted_bdt=bdt.predict(features_test)\n",
    "expected = target_test\n",
    "print(\"Adaboost Accuracy\", accuracy_score(expected,predicted_bdt))\n",
    "print(classification_report(expected, predicted_bdt,target_names=['0', '1']))\n",
    "print(confusion_matrix(expected, predicted_bdt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After employing Adaboosting Classifier on the default Random Forest, and the \n",
    "# best random forest, the accuracy still does not exceed that of the RF Best model.\n",
    "# The RF best model is the preffered Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can visualie the strength of our RF Best model by plotting a ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.881\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC Curve\n",
    "\n",
    "# Determine the false positive and true positive rates\n",
    "fpr, tpr, _ = roc_curve(target_test, rfbest.predict_proba(features_test)[:,1]) \n",
    "    \n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('ROC AUC: %0.3f' % roc_auc)\n",
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ROC represent the lift that is present in the Random Forest model.\n",
    "# With an AUC value reaching close to 1.0 at .881, this acts as an excellent\n",
    "# classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Support Vector Machines - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# train the SVC Linear Default model\n",
    "svm1 = LinearSVC(class_weight='balanced')\n",
    "# fit the SVC Linear Default model\n",
    "svm1 = svm1.fit(features_train, target_train)\n",
    "# testing the SVC Linear Default model\n",
    "target_predicted_svm1 = svm1.predict(features_test)\n",
    "expected = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.7037037  0.81481481 0.75925926 0.72222222 0.8490566  0.79245283\n",
      " 0.37735849 0.79245283 0.79245283 0.75471698]\n",
      "Cross Validation mean score:  0.7358490566037736\n",
      "SVC Linear 1 accuracy score:  0.7591036414565826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79       221\n",
      "           1       0.65      0.79      0.72       136\n",
      "\n",
      "    accuracy                           0.76       357\n",
      "   macro avg       0.75      0.77      0.75       357\n",
      "weighted avg       0.78      0.76      0.76       357\n",
      "\n",
      "[[163  58]\n",
      " [ 28 108]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# cross validate SVC Linear Default model\n",
    "start_time = time.clock()\n",
    "scores_svm1 = cross_val_score(svm1, features_train, target_train, cv=10, scoring='accuracy')\n",
    "print(\"Cross Validation Score for each K\",scores_svm1)\n",
    "print('Cross Validation mean score: ', scores_svm1.mean()) \n",
    "# confusion matrix SVC Linear Default model\n",
    "print(\"SVC Linear 1 accuracy score: \",accuracy_score(target_test,target_predicted_svm1))\n",
    "target_names_svm1 = [\"0\", \"1\"]\n",
    "print(classification_report(target_test, target_predicted_svm1, target_names=target_names_svm1))\n",
    "print(confusion_matrix(target_test, target_predicted_svm1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we can see that the defult returns a 75% accuracy. We will start to\n",
    "# adjust the hyperparameters in search of increasing accuracy statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# train the SVC Linear 2 model\n",
    "svm2 = LinearSVC(class_weight='balanced')\n",
    "# fit the SVC Linear 2 model\n",
    "svm2 = svm2.fit(features_train, target_train)\n",
    "# testing the SVC Linear 2 model\n",
    "target_predicted_svm2 = svm2.predict(features_test)\n",
    "expected = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.77777778 0.83333333 0.74074074 0.74074074 0.73584906 0.77358491\n",
      " 0.77358491 0.77358491 0.79245283 0.67924528]\n",
      "Cross Validation mean score:  0.7620894479385046\n",
      "SVC Linear 2 accuracy score:  0.7703081232492998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       221\n",
      "           1       0.72      0.64      0.68       136\n",
      "\n",
      "    accuracy                           0.77       357\n",
      "   macro avg       0.76      0.75      0.75       357\n",
      "weighted avg       0.77      0.77      0.77       357\n",
      "\n",
      "[[188  33]\n",
      " [ 49  87]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# cross validate SVC Linear 2 model\n",
    "start_time = time.clock()\n",
    "scores_svm2 = cross_val_score(svm2, features_train, target_train, cv=10, scoring='accuracy')\n",
    "print(\"Cross Validation Score for each K\",scores_svm2)\n",
    "print('Cross Validation mean score: ', scores_svm2.mean()) \n",
    "# confusion matrix SVC Linear 2 model\n",
    "print(\"SVC Linear 2 accuracy score: \",accuracy_score(target_test,target_predicted_svm2))\n",
    "target_names_svm2 = [\"0\", \"1\"]\n",
    "print(classification_report(target_test, target_predicted_svm2, target_names=target_names_svm2))\n",
    "print(confusion_matrix(target_test, target_predicted_svm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When changing the weight classes to balanced, we were able to increase the\n",
    "# overall accuracy to 77%, along with recall and f1-score. The precision \n",
    "# decreased from 78% to 77%. \n",
    "# We will now search to increase the maximum iterations in search of incresing\n",
    "# accuracy statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# SVC linear, balanced weight, max iterations\n",
    "\n",
    "# train the SVC Linear  model 3\n",
    "svm3 = LinearSVC(class_weight='balanced', max_iter = 2500)\n",
    "# fit the SVC Linear  model 3\n",
    "svm3 = svm3.fit(features_train, target_train)\n",
    "# testing the SVC Linear  model 3\n",
    "target_predicted_svm3 = svm3.predict(features_test)\n",
    "expected = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.7037037  0.87037037 0.81481481 0.7037037  0.81132075 0.77358491\n",
      " 0.69811321 0.79245283 0.81132075 0.81132075]\n",
      "Cross Validation mean score:  0.7790705800139761\n",
      "SVC Linear 3 accuracy score:  0.7787114845938375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.81       221\n",
      "           1       0.69      0.77      0.73       136\n",
      "\n",
      "    accuracy                           0.78       357\n",
      "   macro avg       0.77      0.78      0.77       357\n",
      "weighted avg       0.79      0.78      0.78       357\n",
      "\n",
      "[[173  48]\n",
      " [ 31 105]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# cross validate SVC Linear model 3\n",
    "start_time = time.clock()\n",
    "scores_svm3 = cross_val_score(svm3, features_train, target_train, cv=10, scoring='accuracy')\n",
    "print(\"Cross Validation Score for each K\",scores_svm3)\n",
    "print('Cross Validation mean score: ', scores_svm3.mean()) \n",
    "# confusion matrix SVC Linear model 3\n",
    "print(\"SVC Linear 3 accuracy score: \",accuracy_score(target_test,target_predicted_svm3))\n",
    "target_names_svm3 = [\"0\", \"1\"]\n",
    "print(classification_report(target_test, target_predicted_svm3, target_names=target_names_svm3))\n",
    "print(confusion_matrix(target_test, target_predicted_svm3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After increasing the maximum iterations up to 2500, from the default 1000,\n",
    "# we were not only able to increase the overall accuracy of the model, but\n",
    "# we were also able to bring the precision statistic back up, to 79%, and also \n",
    "# increase the recall and f-1 score to 78%. This surpasses the previous manual\n",
    "# adjustments in the last notebook. SVC linear model 3 is our preffered \n",
    "# SVC model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# SVC RBF default\n",
    "# train, fit, test SVC model 1\n",
    "start_time = time.clock()\n",
    "svm_rbf1 = SVC(kernel='rbf')\n",
    "print(svm_rbf1)\n",
    "svm_rbf1.fit(features_train, target_train)\n",
    "predicted_rbf1=svm_rbf1.predict(features_test)\n",
    "expected = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.72222222 0.64814815 0.7037037  0.68518519 0.67924528 0.67924528\n",
      " 0.66037736 0.67924528 0.62264151 0.67924528]\n",
      "Cross Validation mean score:  0.6759259259259259\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.93      0.79       221\n",
      "           1       0.71      0.29      0.42       136\n",
      "\n",
      "    accuracy                           0.69       357\n",
      "   macro avg       0.70      0.61      0.60       357\n",
      "weighted avg       0.69      0.69      0.64       357\n",
      "\n",
      "[[205  16]\n",
      " [ 96  40]]\n",
      "0.6862745098039216\n",
      "Time to run 2.460492800000793 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# cross validation and confusion matrix SVC RBF model 1\n",
    "svm_rbf1_CV_scores = cross_val_score(svm_rbf1, features_train, target_train, cv=10,scoring='accuracy')\n",
    "print('Cross Validation Score for each K', svm_rbf1_CV_scores)\n",
    "print('Cross Validation mean score: ', svm_rbf1_CV_scores.mean())\n",
    "\n",
    "target_names_rbf1 = [\"0\", \"1\"]\n",
    "print(classification_report(expected, predicted_rbf1,target_names=target_names_rbf1))\n",
    "print(confusion_matrix(expected, predicted_rbf1))\n",
    "print(accuracy_score(expected,predicted_rbf1))\n",
    "print(\"Time to run\", time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The deafult RBF returns a low accuracy of ~ 68%. We will search to increase\n",
    "# accuracy by tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES {'mean_fit_time': array([0.00578787, 0.00858023, 0.00508611, 0.00987592, 0.00498779,\n",
      "       0.00806925, 0.00529153, 0.00867772, 0.00528648, 0.00847278,\n",
      "       0.00557055, 0.00860002, 0.00547657, 0.00907054, 0.00598922,\n",
      "       0.00886774, 0.00548518, 0.00867836, 0.00568469, 0.00857813,\n",
      "       0.00528409, 0.00857661, 0.00518577, 0.00877612, 0.00628283,\n",
      "       0.00857682, 0.00568457, 0.00867634, 0.00598369, 0.00847704,\n",
      "       0.00618324, 0.00857673, 0.00578439, 0.00947676, 0.00658472,\n",
      "       0.00938158, 0.00688062, 0.00987651, 0.00667772, 0.00930479,\n",
      "       0.00628438, 0.00887167, 0.00628502, 0.0095726 , 0.00687442,\n",
      "       0.00927792, 0.00667694, 0.00897484, 0.01186862, 0.01126876,\n",
      "       0.01067271, 0.01216674, 0.01067052, 0.01116889, 0.01096351,\n",
      "       0.01136925, 0.01077082, 0.01166854, 0.01077089, 0.01126959]), 'std_fit_time': array([4.02071123e-04, 6.66431086e-04, 2.99239254e-04, 1.29684196e-03,\n",
      "       3.93361755e-06, 3.01712687e-04, 4.53443595e-04, 7.81379834e-04,\n",
      "       4.58637182e-04, 4.96197537e-04, 4.86944056e-04, 4.95096033e-04,\n",
      "       5.07289517e-04, 5.30713119e-04, 6.34214064e-04, 6.82558423e-04,\n",
      "       4.98986554e-04, 7.79474831e-04, 4.57053802e-04, 6.62419934e-04,\n",
      "       4.58102231e-04, 9.14159640e-04, 3.98969668e-04, 1.07416575e-03,\n",
      "       6.38713437e-04, 4.88723763e-04, 4.57079804e-04, 4.57194314e-04,\n",
      "       4.46168368e-04, 4.98747871e-04, 7.46454915e-04, 6.61444060e-04,\n",
      "       3.98695611e-04, 6.72109723e-04, 4.91291170e-04, 6.56725548e-04,\n",
      "       5.37144658e-04, 9.44621261e-04, 7.72264904e-04, 1.79998654e-03,\n",
      "       6.38236999e-04, 6.98506677e-04, 4.55745256e-04, 6.58830711e-04,\n",
      "       6.95572875e-04, 1.34478365e-03, 6.42542233e-04, 8.90553317e-04,\n",
      "       1.62473493e-03, 1.54863215e-03, 1.00158121e-03, 1.46131041e-03,\n",
      "       9.98747080e-04, 1.39599305e-03, 1.25424416e-03, 1.35281739e-03,\n",
      "       1.32315358e-03, 1.48259896e-03, 1.16304745e-03, 1.26527675e-03]), 'mean_score_time': array([5.94925880e-04, 3.99184227e-04, 3.99017334e-04, 1.00278854e-03,\n",
      "       6.97731972e-04, 9.99093056e-04, 2.97427177e-04, 8.95738602e-04,\n",
      "       5.00607491e-04, 5.99241257e-04, 0.00000000e+00, 7.90834427e-04,\n",
      "       5.07211685e-04, 4.96172905e-04, 3.98349762e-04, 4.99582291e-04,\n",
      "       2.99119949e-04, 6.96587563e-04, 3.98993492e-04, 4.97269630e-04,\n",
      "       3.00741196e-04, 7.98201561e-04, 8.97884369e-04, 5.98692894e-04,\n",
      "       5.98645210e-04, 5.98597527e-04, 6.98304176e-04, 6.98471069e-04,\n",
      "       2.99358368e-04, 6.98280334e-04, 9.97543335e-05, 6.98328018e-04,\n",
      "       4.98819351e-04, 8.93568993e-04, 4.00543213e-04, 6.93321228e-04,\n",
      "       7.98678398e-04, 7.99107552e-04, 6.02865219e-04, 6.97278976e-04,\n",
      "       2.99334526e-04, 6.98447227e-04, 5.96618652e-04, 1.00431442e-03,\n",
      "       6.00314140e-04, 7.98630714e-04, 2.99048424e-04, 5.98001480e-04,\n",
      "       5.98192215e-04, 5.99217415e-04, 1.98984146e-04, 6.00767136e-04,\n",
      "       2.98762321e-04, 4.98795509e-04, 5.97500801e-04, 4.98914719e-04,\n",
      "       5.98573685e-04, 6.98351860e-04, 3.99088860e-04, 5.98549843e-04]), 'std_score_time': array([4.85840885e-04, 4.88899827e-04, 4.88694445e-04, 4.46294821e-04,\n",
      "       4.56780222e-04, 2.98023224e-06, 4.54353220e-04, 2.98971137e-04,\n",
      "       5.00646875e-04, 4.89288556e-04, 0.00000000e+00, 3.96061658e-04,\n",
      "       5.07368822e-04, 4.96326367e-04, 4.87889376e-04, 4.99584855e-04,\n",
      "       4.56913357e-04, 4.56044040e-04, 4.88665249e-04, 4.97293379e-04,\n",
      "       4.59404122e-04, 3.99100829e-04, 2.99294811e-04, 4.88830741e-04,\n",
      "       4.88791772e-04, 4.88752866e-04, 4.57147410e-04, 4.57256667e-04,\n",
      "       4.57277464e-04, 4.57131784e-04, 2.99263000e-04, 4.57163009e-04,\n",
      "       4.98819358e-04, 5.36352134e-04, 4.90594994e-04, 4.54112357e-04,\n",
      "       3.99344778e-04, 3.99569239e-04, 4.92407920e-04, 4.56479927e-04,\n",
      "       4.57242869e-04, 4.57280734e-04, 4.87171088e-04, 1.62318058e-05,\n",
      "       4.90166582e-04, 3.99318908e-04, 4.56808828e-04, 4.88271480e-04,\n",
      "       4.88422697e-04, 4.89260788e-04, 3.97968307e-04, 4.90553359e-04,\n",
      "       4.56367632e-04, 4.98809861e-04, 4.87859009e-04, 4.98914735e-04,\n",
      "       4.88733538e-04, 4.57178831e-04, 4.88782050e-04, 4.88713917e-04]), 'param_C': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 25, 25, 25, 25,\n",
      "                   25, 25, 25, 25, 25, 25, 25, 25, 30, 30, 30, 30, 30, 30,\n",
      "                   30, 30, 30, 30, 30, 30, 100, 100, 100, 100, 100, 100,\n",
      "                   100, 100, 100, 100, 100, 100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_degree': masked_array(data=[0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 0, 0, 1, 1, 2, 2,\n",
      "                   3, 3, 4, 4, 5, 5, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5,\n",
      "                   0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 0, 0, 1, 1, 2, 2,\n",
      "                   3, 3, 4, 4, 5, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[0.001, 0.1, 0.001, 0.1, 0.001, 0.1, 0.001, 0.1, 0.001,\n",
      "                   0.1, 0.001, 0.1, 0.001, 0.1, 0.001, 0.1, 0.001, 0.1,\n",
      "                   0.001, 0.1, 0.001, 0.1, 0.001, 0.1, 0.001, 0.1, 0.001,\n",
      "                   0.1, 0.001, 0.1, 0.001, 0.1, 0.001, 0.1, 0.001, 0.1,\n",
      "                   0.001, 0.1, 0.001, 0.1, 0.001, 0.1, 0.001, 0.1, 0.001,\n",
      "                   0.1, 0.001, 0.1, 0.001, 0.1, 0.001, 0.1, 0.001, 0.1,\n",
      "                   0.001, 0.1, 0.001, 0.1, 0.001, 0.1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 10, 'degree': 0, 'gamma': 0.001}, {'C': 10, 'degree': 0, 'gamma': 0.1}, {'C': 10, 'degree': 1, 'gamma': 0.001}, {'C': 10, 'degree': 1, 'gamma': 0.1}, {'C': 10, 'degree': 2, 'gamma': 0.001}, {'C': 10, 'degree': 2, 'gamma': 0.1}, {'C': 10, 'degree': 3, 'gamma': 0.001}, {'C': 10, 'degree': 3, 'gamma': 0.1}, {'C': 10, 'degree': 4, 'gamma': 0.001}, {'C': 10, 'degree': 4, 'gamma': 0.1}, {'C': 10, 'degree': 5, 'gamma': 0.001}, {'C': 10, 'degree': 5, 'gamma': 0.1}, {'C': 20, 'degree': 0, 'gamma': 0.001}, {'C': 20, 'degree': 0, 'gamma': 0.1}, {'C': 20, 'degree': 1, 'gamma': 0.001}, {'C': 20, 'degree': 1, 'gamma': 0.1}, {'C': 20, 'degree': 2, 'gamma': 0.001}, {'C': 20, 'degree': 2, 'gamma': 0.1}, {'C': 20, 'degree': 3, 'gamma': 0.001}, {'C': 20, 'degree': 3, 'gamma': 0.1}, {'C': 20, 'degree': 4, 'gamma': 0.001}, {'C': 20, 'degree': 4, 'gamma': 0.1}, {'C': 20, 'degree': 5, 'gamma': 0.001}, {'C': 20, 'degree': 5, 'gamma': 0.1}, {'C': 25, 'degree': 0, 'gamma': 0.001}, {'C': 25, 'degree': 0, 'gamma': 0.1}, {'C': 25, 'degree': 1, 'gamma': 0.001}, {'C': 25, 'degree': 1, 'gamma': 0.1}, {'C': 25, 'degree': 2, 'gamma': 0.001}, {'C': 25, 'degree': 2, 'gamma': 0.1}, {'C': 25, 'degree': 3, 'gamma': 0.001}, {'C': 25, 'degree': 3, 'gamma': 0.1}, {'C': 25, 'degree': 4, 'gamma': 0.001}, {'C': 25, 'degree': 4, 'gamma': 0.1}, {'C': 25, 'degree': 5, 'gamma': 0.001}, {'C': 25, 'degree': 5, 'gamma': 0.1}, {'C': 30, 'degree': 0, 'gamma': 0.001}, {'C': 30, 'degree': 0, 'gamma': 0.1}, {'C': 30, 'degree': 1, 'gamma': 0.001}, {'C': 30, 'degree': 1, 'gamma': 0.1}, {'C': 30, 'degree': 2, 'gamma': 0.001}, {'C': 30, 'degree': 2, 'gamma': 0.1}, {'C': 30, 'degree': 3, 'gamma': 0.001}, {'C': 30, 'degree': 3, 'gamma': 0.1}, {'C': 30, 'degree': 4, 'gamma': 0.001}, {'C': 30, 'degree': 4, 'gamma': 0.1}, {'C': 30, 'degree': 5, 'gamma': 0.001}, {'C': 30, 'degree': 5, 'gamma': 0.1}, {'C': 100, 'degree': 0, 'gamma': 0.001}, {'C': 100, 'degree': 0, 'gamma': 0.1}, {'C': 100, 'degree': 1, 'gamma': 0.001}, {'C': 100, 'degree': 1, 'gamma': 0.1}, {'C': 100, 'degree': 2, 'gamma': 0.001}, {'C': 100, 'degree': 2, 'gamma': 0.1}, {'C': 100, 'degree': 3, 'gamma': 0.001}, {'C': 100, 'degree': 3, 'gamma': 0.1}, {'C': 100, 'degree': 4, 'gamma': 0.001}, {'C': 100, 'degree': 4, 'gamma': 0.1}, {'C': 100, 'degree': 5, 'gamma': 0.001}, {'C': 100, 'degree': 5, 'gamma': 0.1}], 'split0_test_score': array([0.68518519, 0.64814815, 0.68518519, 0.64814815, 0.68518519,\n",
      "       0.64814815, 0.68518519, 0.64814815, 0.68518519, 0.64814815,\n",
      "       0.68518519, 0.64814815, 0.64814815, 0.7037037 , 0.64814815,\n",
      "       0.7037037 , 0.64814815, 0.7037037 , 0.64814815, 0.7037037 ,\n",
      "       0.64814815, 0.7037037 , 0.64814815, 0.7037037 , 0.62962963,\n",
      "       0.7037037 , 0.62962963, 0.7037037 , 0.62962963, 0.7037037 ,\n",
      "       0.62962963, 0.7037037 , 0.62962963, 0.7037037 , 0.62962963,\n",
      "       0.7037037 , 0.64814815, 0.68518519, 0.64814815, 0.68518519,\n",
      "       0.64814815, 0.68518519, 0.64814815, 0.68518519, 0.64814815,\n",
      "       0.68518519, 0.64814815, 0.68518519, 0.68518519, 0.68518519,\n",
      "       0.68518519, 0.68518519, 0.68518519, 0.68518519, 0.68518519,\n",
      "       0.68518519, 0.68518519, 0.68518519, 0.68518519, 0.68518519]), 'split1_test_score': array([0.7037037 , 0.72222222, 0.7037037 , 0.72222222, 0.7037037 ,\n",
      "       0.72222222, 0.7037037 , 0.72222222, 0.7037037 , 0.72222222,\n",
      "       0.7037037 , 0.72222222, 0.85185185, 0.7037037 , 0.85185185,\n",
      "       0.7037037 , 0.85185185, 0.7037037 , 0.85185185, 0.7037037 ,\n",
      "       0.85185185, 0.7037037 , 0.85185185, 0.7037037 , 0.85185185,\n",
      "       0.72222222, 0.85185185, 0.72222222, 0.85185185, 0.72222222,\n",
      "       0.85185185, 0.72222222, 0.85185185, 0.72222222, 0.85185185,\n",
      "       0.72222222, 0.83333333, 0.74074074, 0.83333333, 0.74074074,\n",
      "       0.83333333, 0.74074074, 0.83333333, 0.74074074, 0.83333333,\n",
      "       0.74074074, 0.83333333, 0.74074074, 0.81481481, 0.72222222,\n",
      "       0.81481481, 0.72222222, 0.81481481, 0.72222222, 0.81481481,\n",
      "       0.72222222, 0.81481481, 0.72222222, 0.81481481, 0.72222222]), 'split2_test_score': array([0.7037037 , 0.75925926, 0.7037037 , 0.75925926, 0.7037037 ,\n",
      "       0.75925926, 0.7037037 , 0.75925926, 0.7037037 , 0.75925926,\n",
      "       0.7037037 , 0.75925926, 0.77777778, 0.75925926, 0.77777778,\n",
      "       0.75925926, 0.77777778, 0.75925926, 0.77777778, 0.75925926,\n",
      "       0.77777778, 0.75925926, 0.77777778, 0.75925926, 0.75925926,\n",
      "       0.75925926, 0.75925926, 0.75925926, 0.75925926, 0.75925926,\n",
      "       0.75925926, 0.75925926, 0.75925926, 0.75925926, 0.75925926,\n",
      "       0.75925926, 0.75925926, 0.75925926, 0.75925926, 0.75925926,\n",
      "       0.75925926, 0.75925926, 0.75925926, 0.75925926, 0.75925926,\n",
      "       0.75925926, 0.75925926, 0.75925926, 0.77777778, 0.77777778,\n",
      "       0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778,\n",
      "       0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778]), 'split3_test_score': array([0.68518519, 0.57407407, 0.68518519, 0.57407407, 0.68518519,\n",
      "       0.57407407, 0.68518519, 0.57407407, 0.68518519, 0.57407407,\n",
      "       0.68518519, 0.57407407, 0.7037037 , 0.57407407, 0.7037037 ,\n",
      "       0.57407407, 0.7037037 , 0.57407407, 0.7037037 , 0.57407407,\n",
      "       0.7037037 , 0.57407407, 0.7037037 , 0.57407407, 0.7037037 ,\n",
      "       0.57407407, 0.7037037 , 0.57407407, 0.7037037 , 0.57407407,\n",
      "       0.7037037 , 0.57407407, 0.7037037 , 0.57407407, 0.7037037 ,\n",
      "       0.57407407, 0.7037037 , 0.57407407, 0.7037037 , 0.57407407,\n",
      "       0.7037037 , 0.57407407, 0.7037037 , 0.57407407, 0.7037037 ,\n",
      "       0.57407407, 0.7037037 , 0.57407407, 0.68518519, 0.61111111,\n",
      "       0.68518519, 0.61111111, 0.68518519, 0.61111111, 0.68518519,\n",
      "       0.61111111, 0.68518519, 0.61111111, 0.68518519, 0.61111111]), 'split4_test_score': array([0.79245283, 0.71698113, 0.79245283, 0.71698113, 0.79245283,\n",
      "       0.71698113, 0.79245283, 0.71698113, 0.79245283, 0.71698113,\n",
      "       0.79245283, 0.71698113, 0.8490566 , 0.75471698, 0.8490566 ,\n",
      "       0.75471698, 0.8490566 , 0.75471698, 0.8490566 , 0.75471698,\n",
      "       0.8490566 , 0.75471698, 0.8490566 , 0.75471698, 0.90566038,\n",
      "       0.75471698, 0.90566038, 0.75471698, 0.90566038, 0.75471698,\n",
      "       0.90566038, 0.75471698, 0.90566038, 0.75471698, 0.90566038,\n",
      "       0.75471698, 0.90566038, 0.73584906, 0.90566038, 0.73584906,\n",
      "       0.90566038, 0.73584906, 0.90566038, 0.73584906, 0.90566038,\n",
      "       0.73584906, 0.90566038, 0.73584906, 0.90566038, 0.75471698,\n",
      "       0.90566038, 0.75471698, 0.90566038, 0.75471698, 0.90566038,\n",
      "       0.75471698, 0.90566038, 0.75471698, 0.90566038, 0.75471698]), 'split5_test_score': array([0.71698113, 0.66037736, 0.71698113, 0.66037736, 0.71698113,\n",
      "       0.66037736, 0.71698113, 0.66037736, 0.71698113, 0.66037736,\n",
      "       0.71698113, 0.66037736, 0.73584906, 0.66037736, 0.73584906,\n",
      "       0.66037736, 0.73584906, 0.66037736, 0.73584906, 0.66037736,\n",
      "       0.73584906, 0.66037736, 0.73584906, 0.66037736, 0.75471698,\n",
      "       0.66037736, 0.75471698, 0.66037736, 0.75471698, 0.66037736,\n",
      "       0.75471698, 0.66037736, 0.75471698, 0.66037736, 0.75471698,\n",
      "       0.66037736, 0.75471698, 0.66037736, 0.75471698, 0.66037736,\n",
      "       0.75471698, 0.66037736, 0.75471698, 0.66037736, 0.75471698,\n",
      "       0.66037736, 0.75471698, 0.66037736, 0.75471698, 0.66037736,\n",
      "       0.75471698, 0.66037736, 0.75471698, 0.66037736, 0.75471698,\n",
      "       0.66037736, 0.75471698, 0.66037736, 0.75471698, 0.66037736]), 'split6_test_score': array([0.69811321, 0.67924528, 0.69811321, 0.67924528, 0.69811321,\n",
      "       0.67924528, 0.69811321, 0.67924528, 0.69811321, 0.67924528,\n",
      "       0.69811321, 0.67924528, 0.71698113, 0.66037736, 0.71698113,\n",
      "       0.66037736, 0.71698113, 0.66037736, 0.71698113, 0.66037736,\n",
      "       0.71698113, 0.66037736, 0.71698113, 0.66037736, 0.75471698,\n",
      "       0.66037736, 0.75471698, 0.66037736, 0.75471698, 0.66037736,\n",
      "       0.75471698, 0.66037736, 0.75471698, 0.66037736, 0.75471698,\n",
      "       0.66037736, 0.73584906, 0.66037736, 0.73584906, 0.66037736,\n",
      "       0.73584906, 0.66037736, 0.73584906, 0.66037736, 0.73584906,\n",
      "       0.66037736, 0.73584906, 0.66037736, 0.75471698, 0.64150943,\n",
      "       0.75471698, 0.64150943, 0.75471698, 0.64150943, 0.75471698,\n",
      "       0.64150943, 0.75471698, 0.64150943, 0.75471698, 0.64150943]), 'split7_test_score': array([0.71698113, 0.73584906, 0.71698113, 0.73584906, 0.71698113,\n",
      "       0.73584906, 0.71698113, 0.73584906, 0.71698113, 0.73584906,\n",
      "       0.71698113, 0.73584906, 0.79245283, 0.71698113, 0.79245283,\n",
      "       0.71698113, 0.79245283, 0.71698113, 0.79245283, 0.71698113,\n",
      "       0.79245283, 0.71698113, 0.79245283, 0.71698113, 0.81132075,\n",
      "       0.71698113, 0.81132075, 0.71698113, 0.81132075, 0.71698113,\n",
      "       0.81132075, 0.71698113, 0.81132075, 0.71698113, 0.81132075,\n",
      "       0.71698113, 0.83018868, 0.71698113, 0.83018868, 0.71698113,\n",
      "       0.83018868, 0.71698113, 0.83018868, 0.71698113, 0.83018868,\n",
      "       0.71698113, 0.83018868, 0.71698113, 0.8490566 , 0.69811321,\n",
      "       0.8490566 , 0.69811321, 0.8490566 , 0.69811321, 0.8490566 ,\n",
      "       0.69811321, 0.8490566 , 0.69811321, 0.8490566 , 0.69811321]), 'split8_test_score': array([0.67924528, 0.79245283, 0.67924528, 0.79245283, 0.67924528,\n",
      "       0.79245283, 0.67924528, 0.79245283, 0.67924528, 0.79245283,\n",
      "       0.67924528, 0.79245283, 0.86792453, 0.75471698, 0.86792453,\n",
      "       0.75471698, 0.86792453, 0.75471698, 0.86792453, 0.75471698,\n",
      "       0.86792453, 0.75471698, 0.86792453, 0.75471698, 0.83018868,\n",
      "       0.75471698, 0.83018868, 0.75471698, 0.83018868, 0.75471698,\n",
      "       0.83018868, 0.75471698, 0.83018868, 0.75471698, 0.83018868,\n",
      "       0.75471698, 0.83018868, 0.75471698, 0.83018868, 0.75471698,\n",
      "       0.83018868, 0.75471698, 0.83018868, 0.75471698, 0.83018868,\n",
      "       0.75471698, 0.83018868, 0.75471698, 0.83018868, 0.73584906,\n",
      "       0.83018868, 0.73584906, 0.83018868, 0.73584906, 0.83018868,\n",
      "       0.73584906, 0.83018868, 0.73584906, 0.83018868, 0.73584906]), 'split9_test_score': array([0.73584906, 0.71698113, 0.73584906, 0.71698113, 0.73584906,\n",
      "       0.71698113, 0.73584906, 0.71698113, 0.73584906, 0.71698113,\n",
      "       0.73584906, 0.71698113, 0.79245283, 0.69811321, 0.79245283,\n",
      "       0.69811321, 0.79245283, 0.69811321, 0.79245283, 0.69811321,\n",
      "       0.79245283, 0.69811321, 0.79245283, 0.69811321, 0.83018868,\n",
      "       0.69811321, 0.83018868, 0.69811321, 0.83018868, 0.69811321,\n",
      "       0.83018868, 0.69811321, 0.83018868, 0.69811321, 0.83018868,\n",
      "       0.69811321, 0.8490566 , 0.69811321, 0.8490566 , 0.69811321,\n",
      "       0.8490566 , 0.69811321, 0.8490566 , 0.69811321, 0.8490566 ,\n",
      "       0.69811321, 0.8490566 , 0.69811321, 0.8490566 , 0.67924528,\n",
      "       0.8490566 , 0.67924528, 0.8490566 , 0.67924528, 0.8490566 ,\n",
      "       0.67924528, 0.8490566 , 0.67924528, 0.8490566 , 0.67924528]), 'mean_test_score': array([0.71174004, 0.70055905, 0.71174004, 0.70055905, 0.71174004,\n",
      "       0.70055905, 0.71174004, 0.70055905, 0.71174004, 0.70055905,\n",
      "       0.71174004, 0.70055905, 0.77361985, 0.69860238, 0.77361985,\n",
      "       0.69860238, 0.77361985, 0.69860238, 0.77361985, 0.69860238,\n",
      "       0.77361985, 0.69860238, 0.77361985, 0.69860238, 0.78312369,\n",
      "       0.70045423, 0.78312369, 0.70045423, 0.78312369, 0.70045423,\n",
      "       0.78312369, 0.70045423, 0.78312369, 0.70045423, 0.78312369,\n",
      "       0.70045423, 0.78501048, 0.69856744, 0.78501048, 0.69856744,\n",
      "       0.78501048, 0.69856744, 0.78501048, 0.69856744, 0.78501048,\n",
      "       0.69856744, 0.78501048, 0.69856744, 0.79063592, 0.69661076,\n",
      "       0.79063592, 0.69661076, 0.79063592, 0.69661076, 0.79063592,\n",
      "       0.69661076, 0.79063592, 0.69661076, 0.79063592, 0.69661076]), 'std_test_score': array([0.0315148 , 0.05912565, 0.0315148 , 0.05912565, 0.0315148 ,\n",
      "       0.05912565, 0.0315148 , 0.05912565, 0.0315148 , 0.05912565,\n",
      "       0.0315148 , 0.05912565, 0.06833518, 0.05366248, 0.06833518,\n",
      "       0.05366248, 0.06833518, 0.05366248, 0.06833518, 0.05366248,\n",
      "       0.06833518, 0.05366248, 0.06833518, 0.05366248, 0.07550858,\n",
      "       0.05412412, 0.07550858, 0.05412412, 0.07550858, 0.05412412,\n",
      "       0.07550858, 0.05412412, 0.07550858, 0.05412412, 0.07550858,\n",
      "       0.05412412, 0.07376673, 0.05379469, 0.07376673, 0.05379469,\n",
      "       0.07376673, 0.05379469, 0.07376673, 0.05379469, 0.07376673,\n",
      "       0.05379469, 0.07376673, 0.05379469, 0.06869571, 0.04924792,\n",
      "       0.06869571, 0.04924792, 0.06869571, 0.04924792, 0.06869571,\n",
      "       0.04924792, 0.06869571, 0.04924792, 0.06869571, 0.04924792]), 'rank_test_score': array([25, 31, 25, 31, 25, 31, 25, 31, 25, 31, 25, 31, 19, 43, 19, 43, 19,\n",
      "       43, 19, 43, 19, 43, 19, 43, 13, 37, 13, 37, 13, 37, 13, 37, 13, 37,\n",
      "       13, 37,  7, 49,  7, 49,  7, 49,  7, 49,  7, 49,  7, 49,  1, 55,  1,\n",
      "       55,  1, 55,  1, 55,  1, 55,  1, 55])}\n",
      "BEST SCORE 0.7906359189378057\n",
      "BEST PARAM {'C': 100, 'degree': 0, 'gamma': 0.001}\n",
      "Time to run 5.47060010000132 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# using grid search to find appropropriate cost function and gamma\n",
    "start_time = time.clock()\n",
    "\n",
    "parameters = {'C': [10, 20, 25, 30, 100], 'gamma': [0.001, 0.1], \n",
    "              'degree': [0,1,2,3,4,5]}\n",
    "svr = SVC(kernel='rbf')\n",
    "grid_svm = GridSearchCV(svm_rbf1, parameters, cv=10)\n",
    "grid_svm.fit(features_train, target_train)\n",
    "print(\"SCORES\", grid_svm.cv_results_)\n",
    "print(\"BEST SCORE\", grid_svm.best_score_)\n",
    "print(\"BEST PARAM\", grid_svm.best_params_)\n",
    "print(\"Time to run\", time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.68518519 0.83333333 0.77777778 0.7037037  0.88679245 0.75471698\n",
      " 0.75471698 0.83018868 0.83018868 0.83018868]\n",
      "Cross Validation mean score:  0.7886792452830188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       221\n",
      "           1       0.70      0.70      0.70       136\n",
      "\n",
      "    accuracy                           0.77       357\n",
      "   macro avg       0.76      0.76      0.76       357\n",
      "weighted avg       0.77      0.77      0.77       357\n",
      "\n",
      "[[181  40]\n",
      " [ 41  95]]\n",
      "0.773109243697479\n",
      "Time to run 130.6817471000013 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch suggest c=100, gamma = .001, degree =0\n",
    "svm_rbf2 = SVC(kernel='rbf', C=100, degree=0, class_weight='balanced', gamma=0.001)\n",
    "svm_rbf2.fit(features_train, target_train)\n",
    "predicted_rbf2=svm_rbf2.predict(features_test)\n",
    "expected = target_test\n",
    "\n",
    "# cross validate and confusion matrix SVC RBF model 2\n",
    "svm_rbf2_CV_scores = cross_val_score(svm_rbf2, features_train, target_train, cv=10,scoring='accuracy')\n",
    "print('Cross Validation Score for each K', svm_rbf2_CV_scores)\n",
    "print('Cross Validation mean score: ', svm_rbf2_CV_scores.mean())\n",
    "\n",
    "target_names_rbf2 = [\"0\", \"1\"]\n",
    "print(classification_report(expected, predicted_rbf2,target_names=target_names_rbf2))\n",
    "print(confusion_matrix(expected, predicted_rbf2))\n",
    "print(accuracy_score(expected,predicted_rbf2))\n",
    "print(\"Time to run\", time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After using gridsearch to find gamma, cost function, and degree,\n",
    "# we were able to increase our accuracy significantly to 77%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Artificial Neural Networks / Stochastic Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(7, 7, 7), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(7,7,7))\n",
    "mlp.fit(features_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[186  35]\n",
      " [ 60  76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80       221\n",
      "           1       0.68      0.56      0.62       136\n",
      "\n",
      "    accuracy                           0.73       357\n",
      "   macro avg       0.72      0.70      0.71       357\n",
      "weighted avg       0.73      0.73      0.73       357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(features_test)\n",
    "print(confusion_matrix(target_test,predictions))\n",
    "print(classification_report(target_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with defaults(relu,adam) this Ann model employing a stochastic gradient decsent solver (adam) returns an accuracy of 73% when containing\n",
    "# 7 neurons (n-1 features) at 3 levels. We will continue to adjust the number of neurons and layers to increase accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[187  34]\n",
      " [ 67  69]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79       221\n",
      "           1       0.67      0.51      0.58       136\n",
      "\n",
      "    accuracy                           0.72       357\n",
      "   macro avg       0.70      0.68      0.68       357\n",
      "weighted avg       0.71      0.72      0.71       357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# 2 layers, 7 nodes, defaults\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(7,7))\n",
    "mlp.fit(features_train,target_train)\n",
    "predictions = mlp.predict(features_test)\n",
    "print(confusion_matrix(target_test,predictions))\n",
    "print(classification_report(target_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decreasing the number of layers resulted in a decrease of accuracy when compared\n",
    "# to default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[189  32]\n",
      " [ 41  95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       221\n",
      "           1       0.75      0.70      0.72       136\n",
      "\n",
      "    accuracy                           0.80       357\n",
      "   macro avg       0.78      0.78      0.78       357\n",
      "weighted avg       0.79      0.80      0.79       357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# 3 layers, 8 nodes, defaults\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(8,8,8))\n",
    "mlp.fit(features_train,target_train)\n",
    "predictions = mlp.predict(features_test)\n",
    "print(confusion_matrix(target_test,predictions))\n",
    "print(classification_report(target_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#increasing nodes and layers resulted in an increased accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[191  30]\n",
      " [ 43  93]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       221\n",
      "           1       0.76      0.68      0.72       136\n",
      "\n",
      "    accuracy                           0.80       357\n",
      "   macro avg       0.79      0.77      0.78       357\n",
      "weighted avg       0.79      0.80      0.79       357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# 3 layers, 10 nodes, defaults\n",
    "mlp3 = MLPClassifier(hidden_layer_sizes=(10,10,10))\n",
    "mlp.fit(features_train,target_train)\n",
    "predictions = mlp.predict(features_test)\n",
    "print(confusion_matrix(target_test,predictions))\n",
    "print(classification_report(target_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continued increasing of node sizes results in increased accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[181  40]\n",
      " [ 34 102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83       221\n",
      "           1       0.72      0.75      0.73       136\n",
      "\n",
      "    accuracy                           0.79       357\n",
      "   macro avg       0.78      0.78      0.78       357\n",
      "weighted avg       0.79      0.79      0.79       357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# 3 layers, 20 nodes, defaults\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20,20,20))\n",
    "mlp.fit(features_train,target_train)\n",
    "predictions = mlp.predict(features_test)\n",
    "print(confusion_matrix(target_test,predictions))\n",
    "print(classification_report(target_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I ran five total ANN models. The first default returned a 73% accuracy\n",
    "# and consisted of 3 layers of 7 nodes.\n",
    "# After finding that increasing node sizes and number of layers increased accuracy,\n",
    "# we found the model plateaued after 10 nodes of 3 layers, resulting in an accuracy\n",
    "# of ~ 80%. Our preffered ANN model consists of 10 nodes at 3 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                  max_features=1.0, max_samples=1.0, n_estimators=10,\n",
      "                  n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
      "                  warm_start=False)\n",
      "Cross Validation Score for each K [0.75925926 0.83333333 0.81481481 0.74074074 0.83018868 0.75471698\n",
      " 0.66037736 0.81132075 0.79245283 0.79245283]\n",
      "Cross Validation mean score:  0.7789657582110413\n",
      "Bagging Accuracy 0.7843137254901961\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       221\n",
      "           1       0.75      0.65      0.70       136\n",
      "\n",
      "    accuracy                           0.78       357\n",
      "   macro avg       0.78      0.76      0.76       357\n",
      "weighted avg       0.78      0.78      0.78       357\n",
      "\n",
      "[[192  29]\n",
      " [ 48  88]]\n"
     ]
    }
   ],
   "source": [
    "# train, fit, test bagging 1 model - default\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag = BaggingClassifier()\n",
    "print(bag1)\n",
    "bag.fit(features_train, target_train)\n",
    "bag_predicted=bag.predict(features_test)\n",
    "expected = target_test\n",
    "\n",
    "# cross validation and confusion matrix of bagging model 1\n",
    "bag_CV_scores = cross_val_score(bag, features_train, target_train, cv=10,scoring='accuracy')\n",
    "print('Cross Validation Score for each K', bag_CV_scores)\n",
    "print('Cross Validation mean score: ', bag_CV_scores.mean()) \n",
    "\n",
    "print(\"Bagging Accuracy\", accuracy_score(expected,bag_predicted))\n",
    "print(classification_report(expected, bag_predicted,target_names=[\"0\", \"1\"]))\n",
    "print(confusion_matrix(expected, bag_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default bagging classifier resulted in an accuracy and test statistics \n",
    "# all equaling 78%. We will work to tune parameters to increase this accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                  max_features=1.0, max_samples=1.0, n_estimators=100,\n",
      "                  n_jobs=-1, oob_score=True, random_state=None, verbose=0,\n",
      "                  warm_start=False)\n",
      "Cross Validation Score for each K [0.75925926 0.85185185 0.87037037 0.75925926 0.79245283 0.75471698\n",
      " 0.73584906 0.81132075 0.75471698 0.79245283]\n",
      "Cross Validation mean score:  0.7882250174703005\n",
      "Bagging Accuracy 0.8011204481792717\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       221\n",
      "           1       0.77      0.68      0.72       136\n",
      "\n",
      "    accuracy                           0.80       357\n",
      "   macro avg       0.79      0.78      0.78       357\n",
      "weighted avg       0.80      0.80      0.80       357\n",
      "\n",
      "[[193  28]\n",
      " [ 43  93]]\n"
     ]
    }
   ],
   "source": [
    "# 100 estimators, default\n",
    "clf_bag = BaggingClassifier(n_estimators=100,oob_score=True,n_jobs=-1)\n",
    "print(clf_bag)\n",
    "clf_bag.fit(features_train, target_train)\n",
    "predicted_bag=clf_bag.predict(features_test)\n",
    "expected = target_test\n",
    "\n",
    "# cross validation and confusion matrix of bagging model 2\n",
    "bag_CV_scores = cross_val_score(clf_bag, features_train, target_train, cv=10,scoring='accuracy')\n",
    "print('Cross Validation Score for each K', bag_CV_scores)\n",
    "print('Cross Validation mean score: ', bag_CV_scores.mean()) \n",
    "\n",
    "print(\"Bagging Accuracy\", accuracy_score(expected,predicted_bag))\n",
    "print(classification_report(expected, predicted_bag,target_names=[\"0\", \"1\"]))\n",
    "print(confusion_matrix(expected, predicted_bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when adding 100 estimators, out of bag score - true, jobs =-1,\n",
    "# the accuracy increases to 80% across weighted average of all metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                  max_features=1.0, max_samples=1.0, n_estimators=1000,\n",
      "                  n_jobs=-1, oob_score=True, random_state=None, verbose=0,\n",
      "                  warm_start=False)\n",
      "Cross Validation Score for each K [0.74074074 0.85185185 0.85185185 0.75925926 0.79245283 0.79245283\n",
      " 0.71698113 0.81132075 0.75471698 0.81132075]\n",
      "Cross Validation mean score:  0.7882948986722571\n",
      "Bagging Accuracy 0.8011204481792717\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       221\n",
      "           1       0.77      0.68      0.72       136\n",
      "\n",
      "    accuracy                           0.80       357\n",
      "   macro avg       0.79      0.78      0.78       357\n",
      "weighted avg       0.80      0.80      0.80       357\n",
      "\n",
      "[[193  28]\n",
      " [ 43  93]]\n"
     ]
    }
   ],
   "source": [
    "# 1000 estimators, oob score = true, n jobs = -1\n",
    "\n",
    "clf_bag3 = BaggingClassifier(n_estimators=1000,oob_score=True,n_jobs=-1)\n",
    "print(clf_bag3)\n",
    "clf_bag3.fit(features_train, target_train)\n",
    "predicted_bag=clf_bag3.predict(features_test)\n",
    "expected = target_test\n",
    "\n",
    "# cross validation and confusion matrix of bagging model 3\n",
    "bag_CV_scores3 = cross_val_score(clf_bag3, features_train, target_train, cv=10,scoring='accuracy')\n",
    "print('Cross Validation Score for each K', bag_CV_scores3)\n",
    "print('Cross Validation mean score: ', bag_CV_scores3.mean()) \n",
    "\n",
    "print(\"Bagging Accuracy\", accuracy_score(expected,predicted_bag))\n",
    "print(classification_report(expected, predicted_bag,target_names=[\"0\", \"1\"]))\n",
    "print(confusion_matrix(expected, predicted_bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I ran three bagging classifiers on the data. The default retuned an accuracy of 78%\n",
    "# After adjusting the number of estimators, oob score = true, n_jobs =-1,\n",
    "# the model was able to increase accuracy and recall statistics. \n",
    "# We then increased the number of estimators to 1000. This only increased the\n",
    "# run time of the model, and did not result in an increased accuracy.\n",
    "# Our preffered bagging model consists of 100 estimators, n_jobs =-1, oobscore = true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "Cross Validation Score for each K [0.81481481 0.85185185 0.81481481 0.75925926 0.86792453 0.79245283\n",
      " 0.81132075 0.90566038 0.81132075 0.83018868]\n",
      "Cross Validation mean score:  0.8259608665269044\n",
      "Gradient Boost Accuracy 0.8095238095238095\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       221\n",
      "           1       0.78      0.69      0.73       136\n",
      "\n",
      "    accuracy                           0.81       357\n",
      "   macro avg       0.80      0.79      0.79       357\n",
      "weighted avg       0.81      0.81      0.81       357\n",
      "\n",
      "[[195  26]\n",
      " [ 42  94]]\n"
     ]
    }
   ],
   "source": [
    "# default graident boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc1 = GradientBoostingClassifier()\n",
    "print(GradientBoostingClassifier())\n",
    "gbc1.fit(features_train, target_train)\n",
    "gbc1_predicted = gbc1.predict(features_test)\n",
    "expected = target_test\n",
    "\n",
    "# cross validation and confusion matrix of gradient boosting model 1\n",
    "gbc1_CV_scores = cross_val_score(gbc1, features_train, target_train, cv=10,scoring='accuracy')\n",
    "print('Cross Validation Score for each K', gbc1_CV_scores)\n",
    "print('Cross Validation mean score: ', gbc1_CV_scores.mean())\n",
    "\n",
    "print(\"Gradient Boost Accuracy\", accuracy_score(expected,gbc1_predicted))\n",
    "print(classification_report(expected, gbc1_predicted,target_names=[\"0\", \"1\"]))\n",
    "print(confusion_matrix(expected, gbc1_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our default gradient boosting classifier returned an accuracy and \n",
    "# all recall statistics at 81%. We will work to turne hyperparameters in\n",
    "# search of increasing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.7962963  0.87037037 0.83333333 0.77777778 0.90566038 0.81132075\n",
      " 0.79245283 0.81132075 0.81132075 0.8490566 ]\n",
      "Cross Validation mean score:  0.8258909853249475\n",
      "Gradient Boost Accuracy 0.7899159663865546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84       221\n",
      "           1       0.75      0.67      0.71       136\n",
      "\n",
      "    accuracy                           0.79       357\n",
      "   macro avg       0.78      0.77      0.77       357\n",
      "weighted avg       0.79      0.79      0.79       357\n",
      "\n",
      "[[191  30]\n",
      " [ 45  91]]\n"
     ]
    }
   ],
   "source": [
    "# train, fit, test gradient boosting 2 model; estimators = 500\n",
    "gbc2 = GradientBoostingClassifier(n_estimators=500)\n",
    "gbc2.fit(features_train, target_train)\n",
    "gbc2_predicted = gbc2.predict(features_test)\n",
    "expected = target_test\n",
    "\n",
    "# cross validation and confusion matrix of gradient boosting model 2\n",
    "gbc2_CV_scores = cross_val_score(gbc2, features_train, target_train, cv=10,scoring='accuracy')\n",
    "print('Cross Validation Score for each K', gbc2_CV_scores)\n",
    "print('Cross Validation mean score: ', gbc2_CV_scores.mean())\n",
    "\n",
    "print(\"Gradient Boost Accuracy\", accuracy_score(expected,gbc2_predicted))\n",
    "print(classification_report(expected, gbc2_predicted,target_names=[\"0\", \"1\"]))\n",
    "print(confusion_matrix(expected, gbc2_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.81481481 0.87037037 0.7962963  0.81481481 0.88679245 0.77358491\n",
      " 0.79245283 0.75471698 0.81132075 0.83018868]\n",
      "Cross Validation mean score:  0.8145352900069882\n",
      "Gradient Boost Accuracy 0.7927170868347339\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84       221\n",
      "           1       0.74      0.70      0.72       136\n",
      "\n",
      "    accuracy                           0.79       357\n",
      "   macro avg       0.78      0.77      0.78       357\n",
      "weighted avg       0.79      0.79      0.79       357\n",
      "\n",
      "[[188  33]\n",
      " [ 41  95]]\n"
     ]
    }
   ],
   "source": [
    "# train, fit, test gradient boosting 3 model; learing rate=.5, estimators = 500\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc3 = GradientBoostingClassifier(learning_rate=.5,n_estimators=500)\n",
    "gbc3.fit(features_train, target_train)\n",
    "gbc3_predicted = gbc3.predict(features_test)\n",
    "expected = target_test\n",
    "\n",
    "# cross validation and confusion matrix of gradient boosting model 3\n",
    "gbc3_CV_scores = cross_val_score(gbc3, features_train, target_train, cv=10,scoring='accuracy')\n",
    "print('Cross Validation Score for each K', gbc3_CV_scores)\n",
    "print('Cross Validation mean score: ', gbc3_CV_scores.mean())\n",
    "\n",
    "print(\"Gradient Boost Accuracy\", accuracy_score(expected,gbc3_predicted))\n",
    "print(classification_report(expected, gbc3_predicted,target_names=[\"0\", \"1\"]))\n",
    "print(confusion_matrix(expected, gbc3_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After adding estimators and learning rate, we were not able to increase our accuracy\n",
    "# We will continute to adjust these in search of increasing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.7962963  0.87037037 0.83333333 0.77777778 0.90566038 0.81132075\n",
      " 0.79245283 0.81132075 0.81132075 0.8490566 ]\n",
      "Cross Validation mean score:  0.8258909853249475\n",
      "Gradient Boost Accuracy 0.7927170868347339\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84       221\n",
      "           1       0.75      0.68      0.71       136\n",
      "\n",
      "    accuracy                           0.79       357\n",
      "   macro avg       0.78      0.77      0.78       357\n",
      "weighted avg       0.79      0.79      0.79       357\n",
      "\n",
      "[[191  30]\n",
      " [ 44  92]]\n"
     ]
    }
   ],
   "source": [
    "# train, fit, test gradient boosting 4 model; learing rate=.1, estimators = 500\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc4 = GradientBoostingClassifier(learning_rate=.1,n_estimators=500)\n",
    "gbc4.fit(features_train, target_train)\n",
    "gbc4_predicted = gbc4.predict(features_test)\n",
    "expected = target_test\n",
    "\n",
    "# cross validation and confusion matrix of gradient boosting model 3\n",
    "gbc4_CV_scores = cross_val_score(gbc4, features_train, target_train, cv=10,scoring='accuracy')\n",
    "print('Cross Validation Score for each K', gbc4_CV_scores)\n",
    "print('Cross Validation mean score: ', gbc4_CV_scores.mean())\n",
    "\n",
    "print(\"Gradient Boost Accuracy\", accuracy_score(expected,gbc4_predicted))\n",
    "print(classification_report(expected, gbc4_predicted,target_names=[\"0\", \"1\"]))\n",
    "print(confusion_matrix(expected, gbc4_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.81481481 0.87037037 0.83333333 0.7962963  0.88679245 0.77358491\n",
      " 0.79245283 0.79245283 0.81132075 0.86792453]\n",
      "Cross Validation mean score:  0.8239343116701606\n",
      "Gradient Boost Accuracy 0.7983193277310925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       221\n",
      "           1       0.76      0.69      0.72       136\n",
      "\n",
      "    accuracy                           0.80       357\n",
      "   macro avg       0.79      0.78      0.78       357\n",
      "weighted avg       0.80      0.80      0.80       357\n",
      "\n",
      "[[191  30]\n",
      " [ 42  94]]\n"
     ]
    }
   ],
   "source": [
    "# train, fit, test gradient boosting 5 model; learing rate=.1, estimators = 1000\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc5 = GradientBoostingClassifier(learning_rate=.1,n_estimators=1000)\n",
    "gbc5.fit(features_train, target_train)\n",
    "gbc5_predicted = gbc5.predict(features_test)\n",
    "expected = target_test\n",
    "\n",
    "# cross validation and confusion matrix of gradient boosting model 3\n",
    "gbc5_CV_scores = cross_val_score(gbc5, features_train, target_train, cv=10,scoring='accuracy')\n",
    "print('Cross Validation Score for each K', gbc5_CV_scores)\n",
    "print('Cross Validation mean score: ', gbc5_CV_scores.mean())\n",
    "\n",
    "print(\"Gradient Boost Accuracy\", accuracy_score(expected,gbc5_predicted))\n",
    "print(classification_report(expected, gbc5_predicted,target_names=[\"0\", \"1\"]))\n",
    "print(confusion_matrix(expected, gbc5_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I ran 5 gradient boosting models on the data. The default returned an accuracy of 81\n",
    "# and all recall statistics of 81% as well. We looked to adjust hyperparameters\n",
    "# in search of increasing accuracy.\n",
    "# After adjusting the learning rate and number of estimators, we were unable to increase our accuracy.\n",
    "# Our preffered Gradient Boosting Classifier was the deafult with max_features=1.0, max_samples=1.0, n_estimators=10,\n",
    "# n_jobs=None, oob_score=False, random_state=None, verbose=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.74074074 0.81481481 0.81481481 0.7962963  0.86792453 0.67924528\n",
      " 0.69811321 0.83018868 0.75471698 0.83018868]\n",
      "Cross Validation mean score:  0.7827044025157233\n",
      "Gradient Boost Accuracy 0.7787114845938375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       221\n",
      "           1       0.72      0.69      0.70       136\n",
      "\n",
      "    accuracy                           0.78       357\n",
      "   macro avg       0.77      0.76      0.76       357\n",
      "weighted avg       0.78      0.78      0.78       357\n",
      "\n",
      "[[184  37]\n",
      " [ 42  94]]\n"
     ]
    }
   ],
   "source": [
    "# extra trees default\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "xdt = ExtraTreesClassifier(n_estimators=100, criterion='gini', max_depth=None, \n",
    "                           min_samples_split=2, min_samples_leaf=1, \n",
    "                           min_weight_fraction_leaf=0.0, max_features='auto', \n",
    "                           max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                           min_impurity_split=None, bootstrap=False, oob_score=False,\n",
    "                           n_jobs=None, random_state=None, verbose=0, warm_start=False,\n",
    "                           class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "xdt.fit(features_train, target_train)\n",
    "predicted_xdt=xdt.predict(features_test)\n",
    "expected = target_test\n",
    "\n",
    "# cross validation and confusion matrix of extra trees default\n",
    "xdt_CV_scores = cross_val_score(xdt, features_train, target_train, cv=10,scoring='accuracy')\n",
    "print('Cross Validation Score for each K', xdt_CV_scores)\n",
    "print('Cross Validation mean score: ', xdt_CV_scores.mean())\n",
    "\n",
    "print(\"Gradient Boost Accuracy\", accuracy_score(expected,predicted_xdt))\n",
    "print(classification_report(expected, predicted_xdt,target_names=[\"0\", \"1\"]))\n",
    "print(confusion_matrix(expected, predicted_xdt))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Extra Trees Classifier default returned an accuracy of 78%, along with recall\n",
    "# statistics equalling 78% as well. We will adjust the hyperparameters in\n",
    "# search of increasing accuracy and recall statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.74074074 0.85185185 0.81481481 0.74074074 0.8490566  0.75471698\n",
      " 0.81132075 0.86792453 0.81132075 0.83018868]\n",
      "Cross Validation mean score:  0.807267645003494\n",
      "Gradient Boost Accuracy 0.7927170868347339\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84       221\n",
      "           1       0.74      0.70      0.72       136\n",
      "\n",
      "    accuracy                           0.79       357\n",
      "   macro avg       0.78      0.77      0.78       357\n",
      "weighted avg       0.79      0.79      0.79       357\n",
      "\n",
      "[[188  33]\n",
      " [ 41  95]]\n"
     ]
    }
   ],
   "source": [
    "# Extra trees model 2, max depth =5, weight = balanced\n",
    "xdt = ExtraTreesClassifier(max_depth=5,\n",
    "                         n_estimators=100,class_weight='balanced')\n",
    "xdt.fit(features_train, target_train)\n",
    "predicted_xdt=xdt.predict(features_test)\n",
    "expected = target_test\n",
    "\n",
    "# cross validation and confusion matrix of extra trees model 2\n",
    "xdt_CV_scores = cross_val_score(xdt, features_train, target_train, cv=10,scoring='accuracy')\n",
    "print('Cross Validation Score for each K', xdt_CV_scores)\n",
    "print('Cross Validation mean score: ', xdt_CV_scores.mean())\n",
    "\n",
    "print(\"Gradient Boost Accuracy\", accuracy_score(expected,predicted_xdt))\n",
    "print(classification_report(expected, predicted_xdt,target_names=[\"0\", \"1\"]))\n",
    "print(confusion_matrix(expected, predicted_xdt))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.74074074 0.85185185 0.7962963  0.72222222 0.83018868 0.77358491\n",
      " 0.79245283 0.8490566  0.81132075 0.83018868]\n",
      "Cross Validation mean score:  0.7997903563941299\n",
      "Gradient Boost Accuracy 0.7871148459383753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       221\n",
      "           1       0.73      0.70      0.71       136\n",
      "\n",
      "    accuracy                           0.79       357\n",
      "   macro avg       0.78      0.77      0.77       357\n",
      "weighted avg       0.79      0.79      0.79       357\n",
      "\n",
      "[[186  35]\n",
      " [ 41  95]]\n"
     ]
    }
   ],
   "source": [
    "# Extra trees model 3, max depth =3, weight = balanced\n",
    "xdt = ExtraTreesClassifier(max_depth=3,\n",
    "                         n_estimators=100,class_weight='balanced')\n",
    "xdt.fit(features_train, target_train)\n",
    "predicted_xdt=xdt.predict(features_test)\n",
    "expected = target_test\n",
    "\n",
    "# cross validation and confusion matrix of extra trees model 3\n",
    "xdt_CV_scores = cross_val_score(xdt, features_train, target_train, cv=10,scoring='accuracy')\n",
    "print('Cross Validation Score for each K', xdt_CV_scores)\n",
    "print('Cross Validation mean score: ', xdt_CV_scores.mean())\n",
    "\n",
    "print(\"Gradient Boost Accuracy\", accuracy_score(expected,predicted_xdt))\n",
    "print(classification_report(expected, predicted_xdt,target_names=[\"0\", \"1\"]))\n",
    "print(confusion_matrix(expected, predicted_xdt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decreasing the depth resulted in a decrease in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.7037037  0.85185185 0.81481481 0.74074074 0.8490566  0.77358491\n",
      " 0.81132075 0.8490566  0.83018868 0.81132075]\n",
      "Cross Validation mean score:  0.8035639412997904\n",
      "Gradient Boost Accuracy 0.7899159663865546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       221\n",
      "           1       0.74      0.69      0.71       136\n",
      "\n",
      "    accuracy                           0.79       357\n",
      "   macro avg       0.78      0.77      0.77       357\n",
      "weighted avg       0.79      0.79      0.79       357\n",
      "\n",
      "[[188  33]\n",
      " [ 42  94]]\n"
     ]
    }
   ],
   "source": [
    "# Extra trees model 4, max depth =5, weight = balanced, estimators = 1000\n",
    "xdt = ExtraTreesClassifier(max_depth=5,\n",
    "                         n_estimators=1000,class_weight='balanced')\n",
    "xdt.fit(features_train, target_train)\n",
    "predicted_xdt=xdt.predict(features_test)\n",
    "expected = target_test\n",
    "\n",
    "# cross validation and confusion matrix of extra trees model 4\n",
    "xdt_CV_scores = cross_val_score(xdt, features_train, target_train, cv=10,scoring='accuracy')\n",
    "print('Cross Validation Score for each K', xdt_CV_scores)\n",
    "print('Cross Validation mean score: ', xdt_CV_scores.mean())\n",
    "\n",
    "print(\"Gradient Boost Accuracy\", accuracy_score(expected,predicted_xdt))\n",
    "print(classification_report(expected, predicted_xdt,target_names=[\"0\", \"1\"]))\n",
    "print(confusion_matrix(expected, predicted_xdt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.74074074 0.85185185 0.81481481 0.75925926 0.86792453 0.75471698\n",
      " 0.77358491 0.8490566  0.77358491 0.8490566 ]\n",
      "Cross Validation mean score:  0.8034591194968552\n",
      "Gradient Boost Accuracy 0.8067226890756303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       221\n",
      "           1       0.75      0.74      0.74       136\n",
      "\n",
      "    accuracy                           0.81       357\n",
      "   macro avg       0.80      0.79      0.79       357\n",
      "weighted avg       0.81      0.81      0.81       357\n",
      "\n",
      "[[188  33]\n",
      " [ 36 100]]\n"
     ]
    }
   ],
   "source": [
    "# Extra trees model 5, max depth =10, weight = balanced, estimators = 500\n",
    "xdt = ExtraTreesClassifier(max_depth=10,\n",
    "                         n_estimators=100,class_weight='balanced')\n",
    "xdt.fit(features_train, target_train)\n",
    "predicted_xdt=xdt.predict(features_test)\n",
    "expected = target_test\n",
    "\n",
    "# cross validation and confusion matrix of extra trees model 5\n",
    "xdt_CV_scores = cross_val_score(xdt, features_train, target_train, cv=10,scoring='accuracy')\n",
    "print('Cross Validation Score for each K', xdt_CV_scores)\n",
    "print('Cross Validation mean score: ', xdt_CV_scores.mean())\n",
    "\n",
    "print(\"Gradient Boost Accuracy\", accuracy_score(expected,predicted_xdt))\n",
    "print(classification_report(expected, predicted_xdt,target_names=[\"0\", \"1\"]))\n",
    "print(confusion_matrix(expected, predicted_xdt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I ran five Extra Trees Classifier models on the data. \n",
    "# The default returned a 78% accuracy. We then tuned hyperparameters in search of increasing accuracy.\n",
    "# After increasing max depth, and decreasing estimators back to the default 100,\n",
    "# we were able to increase our accuracy and recall statistic to 81%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82 (+/- 0.03) [Adaboost Random Forest]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76 (+/- 0.07) [SVM]\n",
      "Accuracy: 0.81 (+/- 0.01) [AdaBoost Decision Tree]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82 (+/- 0.02) [Ensemble]\n",
      "Cross Validation Score for each K [0.81308411 0.79439252 0.79439252 0.8411215  0.83962264]\n",
      "Cross Validation mean score:  0.8165226591430083\n"
     ]
    }
   ],
   "source": [
    "# Stack 1, rf best, AdaboostDT, svm model 3\n",
    "clf1 = rfbest1\n",
    "clf2 = svm3 \n",
    "bdt = bdt\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[('rf', clf1), ('svr', clf2), ('bdt', bdt)], voting='hard') \n",
    "for MV, label in zip([clf1, clf2, bdt, eclf2], ['Adaboost Random Forest', 'SVM', 'AdaBoost Decision Tree', 'Ensemble']):\n",
    "\n",
    "    scores = cross_val_score(MV, features_train, target_train, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "print('Cross Validation Score for each K', scores)\n",
    "print('Cross Validation mean score: ', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When stacking our best Random Forest, Adaboosted Decison Tree, and best \n",
    "# SVM, model, the stack returns an accuracy of 82%. We will work to combine\n",
    "# different models and tune parameters in search of increasing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82 (+/- 0.04) [Adaboost Random Forest]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78 (+/- 0.03) [SVM]\n",
      "Accuracy: 0.81 (+/- 0.03) [AdaBoost Decision Tree]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Modeling\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82 (+/- 0.04) [Ensemble]\n",
      "Cross Validation Score for each K [0.77777778 0.83333333 0.81481481 0.75925926 0.8490566  0.79245283\n",
      " 0.77358491 0.86792453 0.8490566  0.8490566 ]\n",
      "Cross Validation mean score:  0.8166317260656883\n"
     ]
    }
   ],
   "source": [
    "# Stack 2, rf best, AdaboostDT, svm model 3, CV = 10\n",
    "clf1 = rfbest1\n",
    "clf2 = svm3 \n",
    "bdt = bdt\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[('rf', clf1), ('svr', clf2), ('bdt', bdt)], voting='hard') \n",
    "for MV, label in zip([clf1, clf2, bdt, eclf2], ['Adaboost Random Forest', 'SVM', 'AdaBoost Decision Tree', 'Ensemble']):\n",
    "\n",
    "    scores2 = cross_val_score(MV, features_train, target_train, cv=10, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores2.mean(), scores2.std(), label))\n",
    "print('Cross Validation Score for each K', scores2)\n",
    "print('Cross Validation mean score: ', scores2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # When stacking our best Random Forest, Adaboosted Decison Tree, and best \n",
    "# SVM, model, the stack returns an accuracy of 82%. We will work to combine\n",
    "# different models and tune parameters in search of increasing accuracy. We will continue to tune our stacks in search of increasing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82 (+/- 0.02) [Random Forest Best]\n",
      "Accuracy: 0.79 (+/- 0.03) [DT Best]\n",
      "Accuracy: 0.83 (+/- 0.01) [AdaBoost Decision Tree]\n",
      "Accuracy: 0.82 (+/- 0.01) [Ensemble]\n",
      "Cross Validation Score for each K [0.8317757  0.81308411 0.80373832 0.8317757  0.82075472]\n",
      "Cross Validation mean score:  0.8202257097513665\n"
     ]
    }
   ],
   "source": [
    "# Stack 3, Random Forest Best, Decision Tree best, graident boosting, CV = 5\n",
    "clf1 = rfbest1\n",
    "clf2 = decision_tree_best \n",
    "gbc1 = gbc1 #gradient boosting\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[('rfbest', clf1), ('dtbest', clf2), ('gbc1', gbc1)], voting='hard') \n",
    "for MV, label in zip([clf1, clf2, gbc1, eclf2], ['Random Forest Best', 'DT Best', 'Gradient Boosting', 'Ensemble']):\n",
    "\n",
    "    scores3 = cross_val_score(MV, features_train, target_train, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores3.mean(), scores3.std(), label))\n",
    "print('Cross Validation Score for each K', scores3)\n",
    "print('Cross Validation mean score: ', scores3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When stacking our best Random Forest, Adaboosted Decison Tree, and best \n",
    "# Gradient Boosting model, the stack returns an accuracy of 82%. We will work to combine\n",
    "# different models and tune parameters in search of increasing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82 (+/- 0.05) [Random Forest Best]\n",
      "Accuracy: 0.82 (+/- 0.03) [DT Best]\n",
      "Accuracy: 0.83 (+/- 0.04) [AdaBoost Decision Tree]\n",
      "Accuracy: 0.83 (+/- 0.04) [Ensemble]\n",
      "Cross Validation Score for each K [0.83333333 0.87037037 0.83333333 0.75925926 0.86792453 0.77358491\n",
      " 0.79245283 0.86792453 0.83018868 0.83018868]\n",
      "Cross Validation mean score:  0.8258560447239691\n"
     ]
    }
   ],
   "source": [
    "# Stack 4, Random Forest Best, Decision Tree best, graident boosting, CV = 10\n",
    "clf1 = rfbest\n",
    "clf2 = decision_tree_best \n",
    "gbc1 = gbc1 #gradient boosting\n",
    "\n",
    "eclf4 = VotingClassifier(estimators=[('rfbest', clf1), ('dtbest', clf2), ('gbc1', gbc1)], voting='hard') \n",
    "for MV, label in zip([clf1, clf2, gbc1, eclf2], ['Random Forest Best', 'DT Best', 'AdaBoost Decision Tree', 'Ensemble']):\n",
    "\n",
    "    scores3 = cross_val_score(MV, features_train, target_train, cv=10, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores3.mean(), scores3.std(), label))\n",
    "print('Cross Validation Score for each K', scores3)\n",
    "print('Cross Validation mean score: ', scores3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After increasing the cross validation score, the stack returned a lesser accuracy\n",
    "# and higher variance. I ran a total of 4 models that consisted of a stack of\n",
    "# many different previous models. The first model consisted of Random Forest\n",
    "# Decision Tree, and SVM models. Individually, these models were the best of their kind.\n",
    "# Combined, they returned 82% accuracy. I then increased the cross validation score of the same\n",
    "# ensemble and it increased the accuracy to 83% however it also increased the variance.\n",
    "# For the third model, I combined the best decision tree, random forest, and gradient boosting\n",
    "# models. This returned an ensemble accuracy of 83%. I then tried to increase the cross \n",
    "# validation score in search of increasing accuracy in my 4th model. This resulted in a\n",
    "# decrease in accuracy, and an increase in variance. The stack number 4 is the preffered\n",
    "# model of all models created at an accuracy of 83%, .04% variance, composed of random forest,\n",
    "# decision tree, and Adaboosted Decision Tree. Ensemble model 3 is all around the best performer,\n",
    "# and I recommend that it be used when searching for the proper survival classification\n",
    "# of passengers on the Titanic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
